% The document class supplies options to control rendering of some standard
% features in the result.  The goal is for uniform style, so some attention 
% to detail is *vital* with all fields.  Each field (i.e., text inside the
% curly braces below, so the MEng text inside {MEng} for instance) should 
% take into account the following:
%
% - author name       should be formatted as "FirstName LastName"
%   (not "Initial LastName" for example),
% - supervisor name   should be formatted as "Title FirstName LastName"
%   (where Title is "Dr." or "Prof." for example),
% - degree programme  should be "BSc", "MEng", "MSci", "MSc" or "PhD",
% - dissertation title should be correctly capitalised (plus you can have
%   an optional sub-title if appropriate, or leave this field blank),
% - dissertation type should be formatted as one of the following:
%   * for the MEng degree programme either "enterprise" or "research" to
%     reflect the stream,
%   * for the MSc  degree programme "$X/Y/Z$" for a project deemed to be
%     X%, Y% and Z% of type I, II and III.
% - year              should be formatted as a 4-digit year of submission
%   (so 2014 rather than the academic year, say 2013/14 say).

\documentclass[ oneside,% the name of the author
                    author={George Herbert},
                % the degree programme: BSc, MEng, MSci or MSc.
                    degree={MSci},
                % the dissertation    title (which cannot be blank)
                     title={Diffusion Models for Time-Evolving Precipitation Fields},
                % the dissertation subtitle (which can    be blank)
                  subtitle={}]{dissertation}

\begin{document}

% =============================================================================

% This macro creates the standard UoB title page by using information drawn
% from the document class (meaning it is vital you select the correct degree 
% title and so on).

\maketitle

% After the title page (which is a special case in that it is not numbered)
% comes the front matter or preliminaries; this macro signals the start of
% such content, meaning the pages are numbered with Roman numerals.

\frontmatter


%\lstlistoflistings

% The following sections are part of the front matter, but are not generated
% automatically by LaTeX; the use of \chapter* means they are not numbered.

% -----------------------------------------------------------------------------

\chapter*{Abstract}

This study presents a diffusion model capable of generating time-evolving precipitation fields, with potential future applications in climate-change simulations and nowcasting. Both domains are of paramount importance: climate-change simulations provide crucial projections to those striving to mitigate the consequences and formulate policies to shape our planet's future; nowcasting supports the real-world socioeconomic needs across various sectors reliant on weather-dependent decision-making.

We employ state-of-the-art techniques from video diffusion models to generate the diffusion model presented in this work. We assess the model's capabilities and limitations and devise techniques to mitigate identified shortcomings. A key finding of our work is that the choice of input transformation applied during the training procedure significantly impacts sample quality. Furthermore, we introduce a novel loss function that facilitates simultaneous optimisation of the input transformation and generative parameters, yielding higher-quality samples than our prior models trained with the standard weighted loss.

In the conditional generation domain, we explore the imputation method and reconstruction-guided sampling to derive a conditional diffusion model approximately from our unconditional model. We use these techniques to enhance the temporal resolution of existing time-evolving precipitation simulations, thus showcasing the potential of diffusion models to decrease the computational cost of time-evolving climate simulations. Our results further demonstrate that reconstruction-guided sampling with a substantial reconstruction-guidance weight produces high-quality interpolated samples that circumvent some of the limitations we observe in our unconditionally generated samples.

Lastly, we provide preliminary results for nowcasting. Our diffusion model generates predictions of future precipitation, whereby the distribution of individual precipitation intensities and spatiotemporal characteristics closely align with those of the corresponding observed samples. We anticipate that these findings will encourage further research in this direction.

% {\bf A compulsory section, of at most 300 words} 
% \vspace{1cm} 

% \noindent
% This section should pr\'{e}cis the project context, aims and objectives,
% and main contributions (e.g., deliverables) and achievements; the same 
% section may be called an abstract elsewhere.  The goal is to ensure the 
% reader is clear about what the topic is, what you have done within this 
% topic, {\em and} what your view of the outcome is.

% The former aspects should be guided by your specification: essentially 
% this section is a (very) short version of what is typically the first 
% chapter. If your project is experimental in nature, this should include 
% a clear research hypothesis.  This will obviously differ significantly
% for each project, but an example might be as follows:

% \begin{quote}
% My research hypothesis is that a suitable genetic algorithm will yield
% more accurate results (when applied to the standard ACME data set) than 
% the algorithm proposed by Jones and Smith, while also executing in less
% time.
% \end{quote}

% \noindent
% The latter aspects should (ideally) be presented as a concise, factual 
% bullet point list.  Again the points will differ for each project, but 
% an might be as follows:

% \begin{quote}
% \noindent
% \begin{itemize}
% \item I spent $120$ hours collecting material on and learning about the 
%       Java garbage-collection sub-system. 
% \item I wrote a total of $5000$ lines of source code, comprising a Linux 
%       device driver for a robot (in C) and a GUI (in Java) that is 
%       used to control it.
% \item I designed a new algorithm for computing the non-linear mapping 
%       from A-space to B-space using a genetic algorithm, see page $17$.
% \item I implemented a version of the algorithm proposed by Jones and 
%       Smith in [6], see page $12$, corrected a mistake in it, and 
%       compared the results with several alternatives.
% \end{itemize}
% \end{quote}

% -----------------------------------------------------------------------------


% \chapter*{Dedication and Acknowledgements}

% {\bf A compulsory section}
% \vspace{1cm} 

% \noindent
% It is common practice (although totally optional) to acknowledge any
% third-party advice, contribution or influence you have found useful
% during your work.  Examples include support from friends or family, 
% the input of your Supervisor and/or Advisor, external organisations 
% or persons who  have supplied resources of some kind (e.g., funding, 
% advice or time), and so on.


% -----------------------------------------------------------------------------

% This macro creates the standard UoB declaration; on the printed hard-copy,
% this must be physically signed by the author in the space indicated.

\makedecl



% -----------------------------------------------------------------------------

% LaTeX automatically generates a table of contents, plus associated lists 
% of figures and tables.  These are all compulsory parts of the dissertation.

\tableofcontents
\listoffigures
% \listoftables

% -----------------------------------------------------------------------------



\chapter*{Ethics Statement}

This project did not require ethical review, as determined by my supervisor Dr Laurence Aitchison.

% {\bf A compulsory section} 
% \vspace{1cm} 

% In almost every project, this will be one of the following statements:
%     \begin{itemize}
%         \item ``This project did not require ethical review, as determined by my supervisor, [fill in name]''; or
%         \item ``This project fits within the scope of ethics application 0026, as reviewed by my supervisor, [fill in name]''; or
%         \item ``An ethics application for this project was reviewed and approved by the faculty research ethics committee as application [fill in number]''.
%     \end{itemize}
    
% See Section 3.2 of the unit Handbook for more information. If something went wrong and none of those three statements apply, then you should instead explain what happened.


% -----------------------------------------------------------------------------

% \chapter*{Supporting Technologies}

% {\bf An optional section}
% \vspace{1cm} 

% \noindent
% This section should present a detailed summary, in bullet point form, 
% of any third-party resources (e.g., hardware and software components) 
% used during the project.  Use of such resources is always perfectly 
% acceptable: the goal of this section is simply to be clear about how
% and where they are used, so that a clear assessment of your work can
% result.  The content can focus on the project topic itself (rather,
% for example, than including ``I used \mbox{\LaTeX} to prepare my 
% dissertation''); an example is as follows:

% \begin{quote}
% \noindent
% \begin{itemize}
% \item I used the Java {\tt BigInteger} class to support my implementation 
%       of RSA.
% \item I used a parts of the OpenCV computer vision library to capture 
%       images from a camera, and for various standard operations (e.g., 
%       threshold, edge detection).
% \item I used an FPGA device supplied by the Department, and altered it 
%       to support an open-source UART core obtained from 
%       \url{http://opencores.org/}.
% \item The web-interface component of my system was implemented by 
%       extending the open-source WordPress software available from
%       \url{http://wordpress.org/}.
% \end{itemize}
% \end{quote}

% -----------------------------------------------------------------------------

\chapter*{Notation}

% {\bf An optional section}
% \vspace{1cm} 

% \noindent
% Any well written document will introduce notation and acronyms before
% their use, {\em even if} they are standard in some way: this ensures 
% any reader can understand the resulting self-contained content.  

% Said introduction can exist within the dissertation itself, wherever 
% that is appropriate.  For an acronym, this is typically achieved at 
% the first point of use via ``Advanced Encryption Standard (AES)'' or 
% similar, noting the capitalisation of relevant letters.  However, it 
% can be useful to include an additional, dedicated list at the start 
% of the dissertation; the advantage of doing so is that you cannot 
% mistakenly use an acronym before defining it.  A limited example is 
% as follows:

\begin{quote}
\noindent
\begin{tabular}{lcl}
%      $\mathbf{X}\circ\mathbf{Y}$ &: & Hadamard product (i.e. element-wise product) of matrices $\mathbf{X}$ and $\mathbf{Y}$\\
      % i.i.d. &: & Independent and identically distributed\\
      % KL &: & Kullback--Leibler\\
      % VAE &: & Variational Autoencoder\\
      % ELBO &: & Evidence Lower Bund\\
      % QQ &: & Quantile-Quantile\\
      % PSD &: & Power Spectral Density\\
      % &\vdots&\\
      $D_{\mathrm{KL}}(P\Vert Q)$ &: & KL divergence of $P$ from $Q$\\
      $\log(x)$ &: & Natural logarithm function (i.e. logarithm with base $e$) applied to $x$\\
      $f\simeq g$ &: & $g$ is an unbiased estimator of $f$\\
      $\mathbf{X}^{\circ n}$ &: & Element-wise exponentiation of matrix $\mathbf{X}$ with power $n$\\
      $\mathrm{diag}(\mathbf{x})$ &: & Diagonal matrix with the values of vector $\mathbf{x}$ on the diagonal\\
% AES                 &:     & Advanced Encryption Standard                                         \\
% DES                 &:     & Data Encryption Standard                                             \\
%                     &\vdots&                                                                      \\
% ${\mathcal H}( x )$ &:     & the Hamming weight of $x$                                            \\
% ${\mathbb  F}_q$    &:     & a finite field with $q$ elements                                     \\
% $x_i$               &:     & the $i$-th bit of some binary sequence $x$, st. $x_i \in \{ 0, 1 \}$ \\
\end{tabular}
\end{quote}


% =============================================================================

% After the front matter comes a number of chapters; under each chapter,
% sections, subsections and even subsubsections are permissible.  The
% pages in this part are numbered with Arabic numerals.  Note that:
%
% - A reference point can be marked using \label{XXX}, and then later
%   referred to via \ref{XXX}; for example Chapter\ref{chap:context}.
% - The chapters are presented here in one file; this can become hard
%   to manage.  An alternative is to save the content in seprate files
%   the use \input{XXX} to import it, which acts like the #include
%   directive in C.

\mainmatter


\chapter{Introduction}
\label{chap:introduction}

\section{Problem Overview}

Climatological data is of paramount importance in the modern world. Driven by the increasingly evident manifestations of climate change, the need for reliable simulations based on emissions scenarios has become increasingly pressing to guide those striving to mitigate the consequences and formulate policies to shape our planet's future. The impact of climatological data extends beyond future projections: nowcasting currently supports real-world socioeconomic needs in various sectors reliant on weather-dependent decision-making \cite{Wilson_Nowcasting_Challenges}.

Despite the importance of climatological data, challenges persist in both domains. High-resolution climate simulations---essential for representing critical features such as hourly rainfall characteristics and assessing the risk of life-threatening events like localised-flash flooding---are too computationally expensive. The computational burden poses a significant barrier to their widespread deployment \cite{MO_CPM}. Meanwhile, in the nowcasting domain, state-of-the-art operational techniques typically utilise radar-based wind estimates to advect precipitation fields, which struggle to capture non-linear events such as convective initiation and heavy precipitation \cite{Ravuri_Skillful_Precipitation_Nowcasting}.

Recent advancements in generative artificial intelligence provide a promising route to alleviate these challenges. Within the computer-vision domain, diffusion models \cite{Deep_Unsupervised_Learning_Sohl-Dickstein, DDPM_Ho, Score_Based_Song} have outperformed previous state-of-the-art models---typically generative adversarial networks (GANs) \cite{Goodfellow_Generative_Adversarial_Networks}---in various tasks, including text-to-image synthesis \cite{Ramesh_Zero-Shot_Text-to-Image_Generation,Rombach_High-Resolution_Image_Synthesis_with_Latent_Diffusion_Models,Imagen_Saharia}, image inpainting \cite{Score_Based_Song,Lugamyr_RePaint} and image super-resolution \cite{Saharia_Image_Super-Resolution_via_Iterative_Refinement,Cascaded_Ho}. In the climate simulations domain, diffusion models have successfully downscaled high-resolution precipitation samples with realistic spatial structures based on low-resolution inputs \cite{Addison_Machine_Learning_Emulation}, thereby presenting a promising method to reduce computational costs. However, diffusion models capable of downscaling currently operate on daily mean snapshots, potentially neglecting critical information in time-evolving data at a high temporal resolution, such as the strong autocorrelation inherent in precipitation and capturing hourly peaks \cite{MO_RCP_Guidance}.

Researchers have recently adapted diffusion models to the video domain \cite{VDM_Ho, Imagen_Video_Ho}, making significant strides towards generating temporally-coherent high-fidelity video. In this work, we build upon these advancements by adopting techniques from video diffusion models to generate time-evolving precipitation fields.

\section{Aims and Ojectives}

We summarise the aims and objectives of this work as follows:
\begin{itemize}
      \item To leverage techniques employed in video diffusion models to develop a diffusion model capable of unconditionally generating time-evolving precipitation fields; and to provide a comprehensive assessment of the model's capabilities and limitations.
      \item To devise methods to address any identified limitations and evaluate the efficacy of these approaches.
      \item To extend the diffusion model for conditional generation and enhance the temporal resolution of existing time-evolving precipitation simulations, thus demonstrating initial proof-of-principle of the capacity for diffusion models to decrease the computational cost of time-evolving climate simulations.
      \item To provide preliminary results for nowcasting to encourage future research in this direction. The current state-of-the-art generative model for nowcasting \cite{Ravuri_Skillful_Precipitation_Nowcasting} is a GAN; we hypothesise that a well-optimised diffusion model will present a more optimal solution, reflecting accomplishments observed in the computer-vision domain.
\end{itemize}

% We summarise the contributions of this work as follows:
% \begin{itemize}
%       \item We provide proof-of-principle results for a diffusion model's capacity to generate time-evolving precipitation fields.
%       \item We demonstrate the importance of selecting a suitable transformation of the input data on the quality of the generated samples. In this vein, we propose a novel loss function that enables the diffusion model to jointly optimise its generative parameters and the transformation applied to the input data.
%       \item We demonstrate the efficacy of reconstruction-guided sampling \cite{VDM_Ho} for temporal interpolation; using an unconditional diffusion model, we derive a conditional diffusion model that can generate hourly precipitation snapshots that maintain coherence with adjacent samples of a bi-hourly temporal resolution. We emphasise the necessity of a suitably high reconstruction-guidance weight to attain this objective.
%       \item We provide preliminary findings in the nowcasting domain, aiming to encourage future research in this area. Given that the current state-of-the-art generative model for nowcasting is a GAN \cite{Ravuri_Skillful_Precipitation_Nowcasting}, we postulate that a well-optimised diffusion model will present a more optimal solution, mirroring the accomplishments observed in the computer-vision domain.
% \end{itemize}

\chapter{Technical Background}
\label{chap:background}

\section{Generative Models}
\label{sec:background_generative}

Let us consider some dataset $\mathcal{D}$ consisting of $N_{\mathcal{D}}\ge1$ datapoints which we assume are independent and identically distributed (i.i.d.):
\begin{align}
      \mathcal{D}=\{\mathbf{x}^{(i)}\mid 1 \le i \le N_{\mathcal{D}}, i \in \mathbb{N} \}
\end{align}
We assume each observed datapoint $\mathbf{x}^{(i)}\in\mathcal{D}$ is a realisation of the observed random variable $\mathbf{x}$ from an underlying process, whose true distribution $p^*(\mathbf{x})$ is unknown. We will omit the index $(i)$ whenever it is clear we are referring to a single datapoint. The goal of \textit{generative modelling} is to approximate this true distribution with a chosen model $p_\theta(\mathbf{x})$ with generative parameters $\theta$. We learn generative parameters $\mathbf{\theta}$ such that the probability distribution function given by the model $p_\theta(\mathbf{x})$ approximates the true distribution of the data, such that for any observed $\mathbf{x}$:
\begin{align}
      p_\theta(\mathbf{x}) \approx p^*(\mathbf{x})
\end{align}
Once learnt, we can generate new samples \textit{unconditionally} from our approximate model at will. We thus refer to the model $p_\theta(\mathbf{x})$ as an unconditional generative model.

\section{Conditional Generation}
\label{sec:background_conditional}

We can extend generative modelling to the conditional setting. We consider each observed $\mathbf{x}$ to have some corresponding conditioning information $\mathbf{c}$. In this context, we wish to approximate the conditional distribution $p^*(\mathbf{x}|\mathbf{c})$. Similar to the unconditional setting, we learn parameters $\theta$ for our model $p_\theta(\mathbf{x}|\mathbf{c})$ such that for any observed $\mathbf{x}$ and conditioning information $\mathbf{c}$:
\begin{align}
      p_\theta(\mathbf{x}|\mathbf{c})\approx p^*(\mathbf{x}|\mathbf{c})
\end{align}
Once learnt, we can generate new samples \textit{conditionally} from our approximate model at will.

One of the most basic cases is a class-conditional generative model, where the conditioning variable $\mathbf{c}$ is simply a class label. In such cases, our conditional model $p_\theta(\mathbf{x}|\mathbf{c})$ has an interpretation as the reverse of a discriminative classification model---a more traditional form of machine learning. As opposed to inputting an observed $\mathbf{x}$ and the model outputting the predicted corresponding class label $\mathbf{c}$, we input a class label $\mathbf{c}$ and use the model to generate a new sample $\mathbf{x}\sim p_\theta(\mathbf{x}|\mathbf{c})$.

Significantly, the conditioning variable $\mathbf{c}$ is not limited to class labels; it can be flexible and take the form of any additional information we wish to condition on to generate samples. A powerful tool in the case of image generation, $\mathbf{c}$ may be a text encoding to facilitate text-to-image synthesis (see e.g. \cite{Imagen_Saharia,Simple_Diffusion_Hoogeboom}). Alternatively, $\mathbf{c}$ may be a lower-resolution image from which we wish to upscale to add higher-resolution details, known as image super-resolution (see e.g. \cite{Cascaded_Ho}).

In this work, we do not explicitly use a conditional model. However, we do derive one approximately from an unconditional model. We discuss this further in Section \ref{sec:background_diffusion_reconstruction_guided_sampling}.

\section{Latent Variables}
\label{sec:background_latent}

We can think of each observed datapoint $\mathbf{x}\in\mathcal{D}$ as being represented or generated via $N_{\mathbf{z}}\ge 1$ associated \textit{latent variables}:
\begin{align}
      \{\mathbf{z}_1,\ldots,\mathbf{z}_{N_\mathbf{z}}\} = \{\mathbf{z}_i \mid i \le 1 \le N_{\mathbf{z}}, i \in \mathbb{N} \}
\end{align}
The latent variables are part of the model, but we do not observe them directly, and they are not within the dataset. We model the joint distribution of the observed variable and the latent variables by $p_\theta(\mathbf{x},\mathbf{z}_1,\ldots,\mathbf{z}_{N_\mathbf{z}})$; the marginal distribution over the observed variable $p_\theta(\mathbf{x})$ is given by:
\begin{align}
      p_\theta(\mathbf{x})=\int p_\theta(\mathbf{x},\mathbf{z}_1,\ldots,\mathbf{z}_{N_\mathbf{z}}) d\mathbf{z}
\end{align}
In the context of a latent-variable model, \textit{generation} refers to the process of sampling the latent variables from the joint distribution $p_\theta(\mathbf{z}_1,\ldots,\mathbf{z}_{N_\mathbf{z}})$, and then sampling the observed variable from the conditional distribution $p_\theta(\mathbf{x}|\mathbf{z}_1,\ldots,\mathbf{z}_{N_\mathbf{z}})$. In the simplest case, we may only have a single latent variable; we omit the index in such cases for notational simplicity.

\section{Likelihood-Based Generative Models}
\label{sec:background_unbiased_objective}

As mentioned in Section \ref{sec:background_generative}, the goal of a generative model is to learn parameters $\theta$ such that $p_\theta(\mathbf{x})\approx p^*(\mathbf{x})$. One way to interpret this is as a minimisation problem. Namely, we wish to learn parameters $\theta$ that minimise the Kullback--Leibler (KL) divergence of the true distribution $p^*(\mathbf{x})$ from our model distribution $p_\theta(\mathbf{x})$:
\begin{align}
      \argmin_\theta D_{\mathrm{KL}}(p^*(\mathbf{x})\Vert p_\theta(\mathbf{x}))
\end{align}
The KL divergence $D_{\mathrm{KL}}$ measures the dissimilarity between two probability distributions; in our case, it provides a measure of the information lost when we approximate the true distribution $p^*(\mathbf{x})$ with our model distribution $p_\theta(\mathbf{x})$.

We can reformulate the KL divergence of the true distribution $p^*(\mathbf{x})$ from our model distribution $p_\theta(\mathbf{x})$ to provide a likelihood-based interpretation:
\begin{align}
      D_{\mathrm{KL}}(p^*(\mathbf{x})\Vert p_\theta(\mathbf{x}))&=\mathbb{E}_{\mathbf{x}\sim p^*(\mathbf{x})}\left[\log\left(\frac{p^*(\mathbf{x})}{p_\theta(\mathbf{x})}\right)\right]\\
      &=\mathbb{E}_{\mathbf{x}\sim p^*(\mathbf{x})}\left[\log p^*(\mathbf{x})\right]+\mathbb{E}_{\mathbf{x}\sim p^*(\mathbf{x})}\left[-\log p_\theta(\mathbf{x})\right]\\
      &=-\mathcal{H}(p^*(\mathbf{x}))+\mathbb{E}_{\mathbf{x}\sim p^*(\mathbf{x})}\left[-\log p_\theta(\mathbf{x})\right]
\end{align}
where $\mathcal{H}{(p^*(\mathbf{x}))}$ is the entropy of the true distribution $p^*(\mathbf{x})$ and is constant. As such, minimisation of the KL divergence in this context equates to minimisation of the expected negative log-likelihood of our model distribution $p_\theta(\mathbf{x})$ with respect to $\mathbf{x}\sim p^*(\mathbf{x})$; formally:
\begin{align}
      \argmin_\theta D_{\mathrm{KL}}(p^*(\mathbf{x})\Vert p_\theta(\mathbf{x}))&=\argmin_\theta \mathbb{E}_{\mathbf{x}\sim p^*(\mathbf{x})}\left[-\log p_\theta(\mathbf{x})\right]
\end{align}
Under the assumption that each of the $N_\mathcal{D}$ samples in our dataset $\mathcal{D}$ are i.i.d. according to $p^*(\mathbf{x})$, we can construct an unbiased estimator:
\begin{align}
      \mathbb{E}_{\mathbf{x}\sim p^*(\mathbf{x})}\left[-\log p_\theta(\mathbf{x})\right]\simeq \frac{1}{N_{\mathcal{D}}}\left(-\log p_\theta(\mathcal{D})\right) = \frac{1}{N_{\mathcal{D}}} \sum_{\mathbf{x}\in\mathcal{D}} \left(-\log p_\theta(\mathbf{x})\right)
\end{align}
In other words, under the i.i.d assumption of $\mathcal{D}$, the mean negative log-likelihood of our model with respect to $\mathcal{D}$ serves as an unbiased estimator of the expected negative log-likelihood of our model with respect to $\mathbf{x}\sim p^*(\mathbf{x})$. In practice, for computational efficiency reasons---as well as GPU memory limitations---we learn via mini-batches $\mathcal{M}\subset \mathcal{D}$ of size $N_\mathcal{M} < N_\mathcal{D}$, each of which are themselves unbiased estimators:
\begin{align}
      \frac{1}{N_\mathcal{D}}\left(-\log p_\theta(\mathcal{D})\right)\simeq \frac{1}{N_\mathcal{M}}\left(-\log p_\theta(\mathcal{M})\right)=\frac{1}{N_\mathcal{M}}\sum_{\mathbf{x}\in\mathcal{M}}\left(-\log p_\theta(\mathbf{x})\right)
\end{align}
As such, by transitivity, the mean negative log-likelihood of our model with respect to each mini-batch $\mathcal{M}$ is itself an unbiased estimator of the expected negative log-likelihood of our model with respect to $\mathbf{x}\sim p^*(\mathbf{x})$. We refer to the broad class of generative models trained to minimise the expected negative log-likelihood of $p_\theta(\mathbf{x})$ with respect to $\mathbf{x}\sim p^*(\mathbf{x})$ as \textit{likelihood-based generative models}.

\section{Variational Autoencoders}
\label{sec:background_vae}

\subsection{Components of the Basic Variational Autoencoder}
\label{sec:background_vae_latent}

The variational autoencoder (VAE) \cite{Autoencoding_Variational_Bayes_Kingma, Stochastic_Backpropagation_Rezende} is an important example of a likelihood-based generative model. In its simplest form, the VAE is a latent-variable model $p_\theta(\mathbf{x},\mathbf{z})$ with a single latent $\mathbf{z}$. We assume that each observed datapoint $\mathbf{x}$ is generated via a two-step process. First, a latent $\mathbf{z}$ is generated from some true prior distribution $p^*(\mathbf{z})$; second, an observed value $\mathbf{x}$ generated from some true conditional distribution $p^*(\mathbf{x}|\mathbf{z})$. Thus, our model $p_\theta(\mathbf{x},\mathbf{z}$) we seek to optimise such that $p_\theta(\mathbf{x})\approx p^*(\mathbf{x})$ takes the following factorised form:
\begin{align}
      p_\theta(\mathbf{x},\mathbf{z})=p_\theta(\mathbf{z})p_\theta(\mathbf{x}|\mathbf{z})
\end{align}
where, naturally, we need to specify our two distributions: $p_\theta(\mathbf{z})$ and $p_\theta(\mathbf{x}|\mathbf{z})$. We refer to $p_\theta(\mathbf{z})$ as the prior over $\mathbf{z}$, and one common choice is the standard Gaussian:
\begin{align}
      p_\theta(\mathbf{z})=\mathcal{N}(\mathbf{z};\mathbf{0}, \mathbf{I})
\end{align}
We refer to $p_\theta(\mathbf{x}|\mathbf{z})$ as the stochastic \textit{decoder} since given a latent $\mathbf{z}$ it produces a distribution over the possible corresponding values of $\mathbf{x}$. As an example, we can select $p_\theta(\mathbf{x}|\mathbf{z})$ be a multivariate Gaussian with diagonal covariance:
\begin{align}
      p_\theta(\mathbf{x}|\mathbf{z})=\mathcal{N}(\mathbf{x}; \boldsymbol{\mu}_\theta (\mathbf{z}), \mathrm{diag}(\boldsymbol\sigma_\theta(\mathbf{z}))^{\circ 2})
\end{align}
where $\boldsymbol{\mu}_\theta(\mathbf{z})$ and $\boldsymbol\sigma_\theta(\mathbf{z})$ are outputs from a neural network with parameters $\theta$. One final, crucial defining feature of the VAE is the stochastic \textit{encoder} $q_\phi(\mathbf{z}|\mathbf{x})$, also referred to as the \textit{inference model}, with variational parameters $\phi$. The stochastic encoder $q_\phi(\mathbf{z}|\mathbf{x})$ approximates the intractable posterior $p_\theta(\mathbf{z}|\mathbf{x})$ of the generative model. Again, a common choice is for $q_\phi(\mathbf{z}|\mathbf{x})$ to be a multivariate Gaussian with diagonal covariance:
\begin{align}
      q_\phi(\mathbf{z}|\mathbf{x})=\mathcal{N}(\mathbf{z}, \boldsymbol{\mu}_\phi(\mathbf{z}), \mathrm{diag}(\boldsymbol\sigma_\phi(\mathbf{z}))^{\circ 2})
\end{align}
Figure \ref{fig:vae} provides a graphical depiction of the VAE.
\begin{figure}[htbp]
      \centering
      \begin{tikzpicture}[->, >=stealth', auto, node distance=3cm, main node/.style={circle, draw, minimum size=1.25cm}]

            % Nodes
            \node[main node] (x) {$\mathbf{x}$};
            \node[main node, right of=x] (z) {$\mathbf{z}$};
      
            % Edges
            \path[]
            (x) edge [bend left, dashed] node[above] {$q_\phi(\mathbf{z}|\mathbf{x})$} (z)
            (z) edge [bend left] node[below] {$p_\theta(\mathbf{x}|\mathbf{z})$} (x);
      \end{tikzpicture}
      \caption{Graphical depiction of basic VAE with one observed variable $\mathbf{x}$ and one latent variable $\mathbf{z}$. The solid line depicts the Bayesian network of the generative model; the dashed line depicts the Bayesian network of the approximate inference model.}
      \label{fig:vae}
\end{figure}

\subsection{Evidence Lower Bound Objective}
\label{sec:background_vae_elbo}

The VAE falls into the broad class of likelihood-based generative models. However, the likelihood $p_\theta(\mathbf{x})$ cannot be optimised directly because the VAE model does not make common simplifying assumptions about marginal and posterior probabilities. Notably, we assume the model's marginal likelihood $p(\mathbf{x})$ does not have an analytic solution or efficient estimator; it is given by:
\begin{align}
      p_\theta(\mathbf{x}) = \int p_\theta(\mathbf{x}|\mathbf{z})p_\theta(\mathbf{z}) d\mathbf{z}
\end{align}
In addition, we assume the model's posterior density $p_\theta(\mathbf{z}|\mathbf{x})$ is intractable, so we cannot employ the expectation-maximisation algorithm.

Not making these simplifying assumptions is the reason for introducing the inference model $q_\phi(\mathbf{z}|\mathbf{x})$ to approximate the model's intractable posterior $p_\theta(\mathbf{z}|\mathbf{x})$. With the introduction of the inference model, we can derive a variational bound on the negative log-likelihood:
\begin{align}
      -\log p_\theta(\mathbf{x})&=\mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z}|\mathbf{x})}\left[-\log p_\theta(\mathbf{x})\right]\\
      &=\mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z}|\mathbf{x})}\left[-\log\left(\frac{p_\theta(\mathbf{x},\mathbf{z})}{p_\theta(\mathbf{z}|\mathbf{x})}\right)\right]\\
      &=\mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z}|\mathbf{x})}\left[-\log\left(\frac{p_\theta(\mathbf{x},\mathbf{z})q_\phi(\mathbf{z}|\mathbf{x})}{p_\theta(\mathbf{z}|\mathbf{x})q_\phi(\mathbf{z}|\mathbf{x})}\right)\right]\\
      &=\mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z}|\mathbf{x})}\left[-\log\left(\frac{p_\theta(\mathbf{x},\mathbf{z})}{q(\mathbf{z}|\mathbf{x})}\right)\right]-\mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z}|\mathbf{x})}\left[\log\left(\frac{q(\mathbf{z}|\mathbf{x})}{p_\theta(\mathbf{z}|\mathbf{x})}\right)\right]\\
      &=\mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z}|\mathbf{x})}\left[-\log\left(\frac{p_\theta(\mathbf{x},\mathbf{z})}{q(\mathbf{z}|\mathbf{x})}\right)\right]-D_{\mathrm{KL}}(q_\phi(\mathbf{z}|\mathbf{x})\Vert p_\theta(\mathbf{z}|\mathbf{x}))
      \label{eq:vae_elbo}
      % &\ge \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z}|\mathbf{x})}\left[\log\left(\frac{p_\theta(\mathbf{x},\mathbf{z})}{q(\mathbf{z}|\mathbf{x})}\right)\right]
\end{align}
The second term in Equation \ref{eq:vae_elbo} is the KL divergence of $q_\phi(\mathbf{z}|\mathbf{x})$ and $p_\theta(\mathbf{z}|\mathbf{x})$ and is non-negative:
\begin{align}
      D_{\mathrm{KL}}(q_\phi(\mathbf{z}|\mathbf{x})\Vert p_\theta(\mathbf{z}|\mathbf{x}))\ge 0
\end{align}
and zero if and only if $q_\phi(\mathbf{z}|\mathbf{x})=p_\theta(\mathbf{z}|\mathbf{x})$. The first term in Equation \ref{eq:vae_elbo} is the additive inverse of the \textit{evidence lower bound objective} (ELBO); in this work, we will refer to this as the ELBO loss, denoted $\mathcal{L}_{\mathrm{ELBO}}$. By the non-negativity of the KL divergence, it serves as a variational bound on the negative log-likelihood of the observed variable $\mathbf{x}$:
\begin{align}
      -\log p_\theta(\mathbf{x})&\le \mathcal{L}_{\mathrm{ELBO}}(\mathbf{x})\\
      &=\mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z}|\mathbf{x})}\left[-\log\left(\frac{p_\theta(\mathbf{x},\mathbf{z})}{q(\mathbf{z}|\mathbf{x})}\right)\right]
\end{align}
As such, minimisation of the ELBO loss accomplishes two things. Firstly, it will approximately minimise the negative log-likelihood of the observed variable $\mathbf{x}$---the overriding goal of a likelihood-based generative model. Secondly, it will minimise the KL divergence of $q_\phi(\mathbf{z}|\mathbf{x})$ from $p_\theta(\mathbf{z}|\mathbf{x})$, thus encouraging the approximate posterior $q_\phi(\mathbf{z}|\mathbf{x})$ to approximate the true posterior $p_\theta(\mathbf{z}|\mathbf{x})$ as closely as possible. 

\subsection{Markovian Hierarchical Variational Autoencoders}
\label{sec:background_vae_hierarchical}

The Markovian hierarchical variational autoencoder (MHVAE) \cite{Improved_Variational_Inference_Kingma, Ladder_VAEs_Sonderby} is a versatile extension of the VAE, accommodating an unrestricted number $N_\mathbf{z}\ge 1$ of latent variables. Notably, the joint distribution of the observed variable and the latent variables is Markovian:
\begin{align}
      p_\theta(\mathbf{x}, \mathbf{z}_1,\ldots,\mathbf{z}_{N_{\mathbf{z}}})=p(\mathbf{x}|\mathbf{z}_1)p_\theta(\mathbf{z}_{N_\mathbf{z}})\prod_{i=1}^{N_{\mathbf{z}}-1}p_\theta(\mathbf{z}_i|\mathbf{z}_{i+1})
\end{align}
Figure \ref{fig:mhvae} illustrates the MHVAE model. For the generative model, the observed variable $\mathbf{x}$ is conditionally independent of $\mathbf{z}_2$ and $\mathbf{z}_3$ given $\mathbf{z}_1$. Similarly, $\mathbf{z}_1$ is conditionally independent of $\mathbf{z}_3$ given $\mathbf{z}_2$.
\begin{figure}[htbp]
      \centering
      \begin{tikzpicture}[->, >=stealth', auto, node distance=3cm, main node/.style={circle, draw, minimum size=1.25cm}]

            % Nodes
            \node[main node] (x) {$\mathbf{x}$};
            \node[main node, right of=x] (z1) {$\mathbf{z}_1$};
            \node[main node, right of=z1] (z2) {$\mathbf{z}_2$};
            \node[main node, right of=z2] (z3) {$\mathbf{z}_3$};

            % Edges
            \path[]
            (x) edge [bend left, dashed] node[above] {$q_\phi(\mathbf{z}_1|\mathbf{x})$} (z1)
            (z1) edge [bend left] node[below] {$p_\theta(\mathbf{x}|\mathbf{z}_1)$} (x)
            (z1) edge [bend left, dashed] node[above] {$q_\phi(\mathbf{z}_2|\mathbf{z}_1)$} (z2)
            (z2) edge [bend left] node[below] {$p_\theta(\mathbf{z}_1|\mathbf{z}_2)$} (z1)
            (z2) edge [bend left, dashed] node[above] {$q_\phi(\mathbf{z}_3|\mathbf{z}_2)$} (z3)
            (z3) edge [bend left] node[below] {$p_\theta(\mathbf{z}_2|\mathbf{z}_3)$} (z2);
      \end{tikzpicture}
      \caption{Graphical depiction of Markovian hierarchical VAE with one observed variable $\mathbf{x}$ and three latent variables $\mathbf{z}_1$, $\mathbf{z}_2$ and $\mathbf{z}_3$. Solid lines depict the Bayesian network of the generative model; dashed lines depict the Bayesian network of the approximate inference model.}
      \label{fig:mhvae}
\end{figure}

\subsection{Infinitely Deep Markovian Hierarchical Variational Autoencoders}
\label{sec:background_vae_infinite}

In the limit of $N_\mathbf{z}\to\infty$, we instead notationally write our latent variables in terms of a continuous-time variable $t\in[0,1]$ as:
\begin{align}
      \{\mathbf{z}_0,\ldots,\mathbf{z}_1\}=\{\mathbf{z}_t\mid t\in[0,1]\}
\end{align}
We can formulate the ELBO loss for the continuous-time MHVAE as follows:
\begin{align}
      -\log p_\theta(\mathbf{x})&\le \mathcal{L}_{\mathrm{ELBO}}(\mathbf{x})\\
      &=\mathbb{E}_{\mathbf{z}_0,\ldots,\mathbf{z}_1\sim q_\phi(\mathbf{z}_0,\ldots,\mathbf{z}_1|\mathbf{x})}\left[-\log\left(\frac{p_\theta(\mathbf{x},\mathbf{z}_0,\ldots,\mathbf{z}_1)}{q_\phi(\mathbf{z}_0,\ldots,\mathbf{z}_1|\mathbf{x})}\right) \right]\\
      &=\mathbb{E}_{\mathbf{z}_0\sim q(\mathbf{z}_0,\mathbf{x})}\left[-\log p_\theta(\mathbf{x}|\mathbf{z}_0)\right]+D_{\mathrm{KL}}(q(\mathbf{z}_0,\ldots,\mathbf{z}_1|\mathbf{x})\Vert p_\theta (\mathbf{z}_0,\ldots,\mathbf{z}_1))
\end{align}
Per datapoint $\mathbf{x}$, we define $\mathcal{L}_T(t)$ as the KL divergence of $q_\phi(\mathbf{z}_t,\ldots,\mathbf{z}_1|\mathbf{x})$ from $p_\theta(\mathbf{z}_t,\ldots,\mathbf{z}_1)$ for a subset of timesteps from $t$ to 1, and its corresponding time derivative $\mathcal{L}_T'(t)$ as:
\begin{align}
      \mathcal{L}_T(t)&=D_{\mathrm{KL}}(q_\phi(\mathbf{z}_t,\ldots,\mathbf{z}_1|\mathbf{x})\Vert p_\theta(\mathbf{z}_t,\ldots,\mathbf{z}_1))\label{eq:dkl_t}\\
      \mathcal{L}_T'(t)&=\frac{d}{dt}\mathcal{L}_T(t)
\end{align}
We can substitute this into the ELBO loss and use the second fundamental theorem of calculus to yield the following form for the ELBO loss, defined per datapoint $\mathbf{x}$ as:
\begin{align}
      \mathcal{L}_{\mathrm{ELBO}}(\mathbf{x})&=\mathbb{E}_{\mathbf{z}_0\sim q(\mathbf{z}_0,\mathbf{x})}\left[-\log p_\theta(\mathbf{x}|\mathbf{z}_0)\right]+D_{\mathrm{KL}}(q(\mathbf{z}_0,\ldots,\mathbf{z}_1|\mathbf{x})\Vert p_\theta (\mathbf{z}_0,\ldots,\mathbf{z}_1))\\
      &=\mathbb{E}_{\mathbf{z}_0\sim q(\mathbf{z}_0,\mathbf{x})}\left[-\log p_\theta(\mathbf{x}|\mathbf{z}_0)\right]+\mathcal{L}_T(0)\\
      &=\mathbb{E}_{\mathbf{z}_0\sim q(\mathbf{z}_0,\mathbf{x})}\left[-\log p_\theta(\mathbf{x}|\mathbf{z}_0)\right]+\mathcal{L}_T(1)-\int_0^1\mathcal{L}'_T(t)\mathrm{d}t \label{eq:elbo_mhvae}
\end{align}
This form for the ELBO may seem unconventional. However, we introduce it here to motivate a strong theoretical link between the ELBO and the weighted loss \cite{Understanding_Diffusion_Objective_Kingma}, which is used to train diffusion models in the broader literature. We explore the weighted loss in Section \ref{sec:background_diffusion_weighted_loss}.

\section{Score-Based Generative Models}
\label{sec:background_score}

% \subsection{Score Networks}
% \label{sec:background_score_score_network}

Score-based generative models \cite{Generative_Modelling_By_Estimating_Gradients_Song, Score_Based_Song} are an alternative to likelihood-based generative models. We define the $score$ of a probability density $p(\mathbf{x})$ to be:
\begin{align}
      \nabla_{\mathbf{x}} \log p(\mathbf{x})
\end{align}
The \textit{score network} $\mathbf{s}_\theta$ is a neural network parameterised by $\theta$ trained to approximate the score of the true data distribution $p^*(\mathbf{x})$, such that for any observed $\mathbf{x}$:
\begin{align}
      \mathbf{s}_\theta(\mathbf{x})\approx \nabla_{\mathbf{x}} \log p^*(\mathbf{x})
\end{align}
Importantly, we accomplish this without training a model to directly approximate the true data distribution $p^*(\mathbf{x})$ in advance.

% \subsection{Example: Denoising Score Matching with Langevin Dynamics}
% \label{sec:background_score_denoising}

% Denoising score matching with Langevin dynamics (SMLD) \cite{Generative_Modelling_By_Estimating_Gradients_Song} is an example of a score-based generative model that enables us to generate data starting from Gaussian noise. While we do not use SMLD explicitly in this work, we introduce it here to better motivate techniques employed in the diffusion model described in Section \ref{sec:background_diffusion}. We introduce SMLD in continuous time. Let us consider a set of positive noise scales:
% \begin{align}
%       \{ \sigma_t \mid t\in[0,1] \}
% \end{align}
% such that $\sigma_t$ is a strictly monotonically increasing function of time $t\in[0,1]$. For each noise scale $\sigma_t$, we define a corresponding Gaussian noise perturbation kernel:
% \begin{align}
%       q(\mathbf{z}_t|\mathbf{x})=\mathcal{N}\left(\mathbf{z}_t; \mathbf{x}, \sigma_t^2\mathbf{I}\right)
% \end{align}
% For all $t\in[0,1]$ the marginal distribution $q(\mathbf{z}_t)$ is given by:
% \begin{align}
%       q(\mathbf{z}_t)=\int p^*(\mathbf{x})q(\mathbf{z}_t|\mathbf{x})
% \end{align}
% We define $\sigma_0 = \sigma_{\min}$ and $\sigma_1 = \sigma_{\max}$ such that:
% \begin{align}
%       q(\mathbf{z}_0)&\approx p^*(\mathbf{x})\\
%       q(\mathbf{z}_1)&\approx\mathcal{N}(\mathbf{z}_1;\mathbf{0}, \sigma_{1}^2\mathbf{I})
% \end{align}
% We train a noise-conditional score network $\mathbf{s}_\theta(\mathbf{z}_t, \sigma)$ such that:
% \begin{align}
%       \mathbf{s}_\theta(\mathbf{z}_t, \sigma_t)\approx \nabla_{\mathbf{z}_t} \log q(\mathbf{z}_t)
% \end{align}
% For our generative model, we start by sampling $\mathbf{z}_1\sim \mathcal{N}(\mathbf{z}_1; \mathbf{0}, \sigma_{1}^2\mathbf{I})$ from an isotropic Gaussian distribution with variance $\sigma_1^2=\sigma_{\max}^2$. Then, we sequentially generate $\mathbf{z}_s$ from $\mathbf{z}_t$ where $0\le s < t \le 1$ via Langevin Markov chain Monte Carlo:
% \begin{align}
%       \mathbf{z}_s = \mathbf{z}_t + \frac{1}{2}\tau_t \mathbf{s}_\theta(\mathbf{z}_t, \sigma_t)+\sqrt{\tau_t}\boldsymbol\epsilon
% \end{align}
% where $\tau_t>0$ is a pre-defined time-dependent step size and $\boldsymbol\epsilon\sim\mathcal{N}(\mathbf{0}, \mathbf{I})$ is multivariate standard Gaussian noise.

\section{Diffusion Models}
\label{sec:background_diffusion}

Diffusion models \cite{Deep_Unsupervised_Learning_Sohl-Dickstein, DDPM_Ho, Score_Based_Song} are a framework for generative modelling. Diffusion models consist of a \textit{forward diffusion process} that transforms a datapoint into noise, and a \textit{reverse-time generative model} able to transform noise back into a datapoint. As we explore in this section, diffusion models have both likelihood and score-based interpretations.

\subsection{Forward Diffusion Process}
\label{sec:background_diffusion_forward}

Specified in continuous time, the \textit{forward diffusion process} is a Gaussian diffusion process that defines the model's latent variables as a sequence of increasingly noisy versions of $\mathbf{x}$; we denote the latent variables by:
\begin{align}
      \{\mathbf{z}_0,\ldots,\mathbf{z}_1\}=\{\mathbf{z}_t\mid t\in[0,1]\}
\end{align}
We can model the time evolution of the diffusion process as the solution to an It\^{o} stochastic differential equation (SDE) \cite{Score_Based_Song}:
\begin{align}
      d\mathbf{z}_t=\mathbf{f}(\mathbf{z}_t,t)dt + g(t)d\mathbf{w}_t\label{eq:forward_sde}
\end{align}
where $\mathbf{w}_t$ is the standard Wiener process (i.e. Brownian motion); $D$ is the dimensionality of our input data; $\mathbf{f}(\mathbf{z}_t, t):\mathbb{R}^D\to\mathbb{R}^D$ is a vector-valued function called the \textit{drift} coefficient of $\mathbf{z}_t$; and $g(t):\mathbb{R}\to\mathbb{R}$ is a scalar-function known as the \textit{diffusion} coefficient of $\mathbf{z}_t$. In this work, we use a \textit{variance-preserving} diffusion model \cite{DDPM_Ho}, which we define by the following drift and diffusion coefficients:
\begin{align}
      \mathbf{f}(\mathbf{z}_t,t)&=-\frac{1}{2}\left(\frac{d}{dt}\log\left(1+\exp(-\lambda_t)\right)\right)\mathbf{z}_t\\
      g(t)^2&=\frac{d}{dt}\log\left(1+\exp(-\lambda_t)\right)\label{eq:diffusion_coefficient_scalar}
\end{align}
where $\lambda_t\in[\lambda_{\min}, \lambda_{\max}]$ is a monotonically-decreasing scalar-valued function of time $t\in[0,1]$; we provide more details on $\lambda_t$ in Section \ref{sec:background_diffusion_noise_schedule}. The forward process forms a conditional joint distribution $q(\mathbf{z}_0,\ldots,\mathbf{z}_1|\mathbf{x})$, whose marginal distribution of each latent variable $\mathbf{z}_t$ given the observed variable $\mathbf{x}$ is given by:
\begin{align}
      q(\mathbf{z}_t|\mathbf{x})=\mathcal{N}\left(\mathbf{z}_t;\alpha_t\mathbf{x},\sigma_t^2\mathbf{I}\right)
      \label{eq:q_z_t_given_x}
\end{align}
where $\alpha_t$ and $\sigma_t$ are functions of $\lambda_t$, such that:
\begin{align}
      \alpha_t^2 = S(\lambda_t)\quad\text{and}\quad\sigma_t^2 = S(-\lambda_t)
\end{align}
where $S$ is the sigmoid function. The joint distribution of latent variables $\mathbf{z}_r,\mathbf{z}_s,\mathbf{z}_t$ at subsequent timesteps $0\le r < s < t \le 1$ is Markovian, and thus:
\begin{align}
      q(\mathbf{z}_t|\mathbf{z}_s,\mathbf{z}_r)&=q(\mathbf{z}_t|\mathbf{z}_s)=\mathcal{N}\left(\mathbf{z}_t; \alpha_{t|s}\mathbf{z}_s, \sigma_{t|s}^2\mathbf{I}\right)
\end{align}
where $\alpha_{t|s}$ and $\sigma_{t|s}$ are given by:
\begin{align}
      \alpha_{t|s} = \frac{\alpha_t}{\alpha_s}\quad\mathrm{and}\quad \sigma_{t|s}^2 = \sigma_t^2-\alpha_{t|s}^2\sigma_s^2
\end{align}
The joint distribution of the forward model $q(\mathbf{z}_0,\ldots,\mathbf{z}_1)$ is defined by the true distribution $p^*(\mathbf{x})$ with the conditional joint distribution $q(\mathbf{z}_0,\ldots,\mathbf{z}_1|\mathbf{x})$:
\begin{align}
      q(\mathbf{z}_0,\ldots,\mathbf{z}_1)=\int p^*(\mathbf{x}) q(\mathbf{z}_0,\ldots,\mathbf{z}_1|\mathbf{x}) d\mathbf{x}
\end{align}

\subsection{Noise Schedule}
\label{sec:background_diffusion_noise_schedule}

We formalise the notion that $\mathbf{z}_t$ is increasingly noisy by defining the log signal-to-noise ratio
\begin{align}
      \lambda_t = \log\left( \frac{\alpha_t^2}{\sigma_t^2}\right)\in[\lambda_{\min}, \lambda_{\max}]
\end{align}
as a strictly monotonically decreasing function $f_{\Lambda}$ of time $t\in[0, 1]$, known as the \textit{noise schedule}.

In this work, we use a truncated continuous-time version of the $\alpha$-cosine schedule \cite{IDDPM_Nichol}, introduced in its original discrete-time form by Nichol and Dhariwal \cite{IDDPM_Nichol}. The $\alpha$-cosine schedule was motivated by the fact that the `linear' schedule introduced in prior work by Ho et al. \cite{DDPM_Ho} causes $\alpha_t$ to fall to zero more quickly than is optimal. Nichol and Dhariwal empirically found that this induces too much noise in the latter stages of the forward diffusion process; as such, the latent variables $\mathbf{z}_t$ in these stages contribute little to sample quality. In response, they proposed the original discrete-time $\alpha$-cosine schedule. In this work, we use a continuous-time diffusion model and therefore use an adapted model described in \cite{Simple_Diffusion_Hoogeboom}. More formally, we define:
\begin{align}
      \lambda_t=f_{\Lambda}(t)=-2\log\left(\tan\left(\frac{\pi}{2}(t_0+t(t_1-t_0))\right)\right)
      \label{eq:f_lambda_alpha_cosine}
\end{align} 
where $t_0$ and $t_1$ truncate $f_{\Lambda}(t)$ to the desired range $[\lambda_{\min}, \lambda_{\max}]$ for $t\in[0,1]$, and are themselves defined as:
\begin{align}
      t_0&=\frac{2}{\pi}\arctan\left(\exp\left(-\frac{1}{2}\lambda_{\max}\right)\right)\\
      t_1&=\frac{2}{\pi}\arctan\left(\exp\left(-\frac{1}{2}\lambda_{\min}\right)\right)
\end{align}
We can compute $\alpha_t$ and $\sigma_t$ from either $\lambda_t$ or $t$ by the following relationships:
\begin{alignat}{2}
      \alpha_t&=\sqrt{S(\lambda_t)}&&=\cos\left(\frac{\pi}{2}(t_0+t(t_1-t_0)\right)\label{eq:alpha_t_alpha_cosine}\\
      \sigma_t&=\sqrt{S(-\lambda_t)}&&=\sin\left(\frac{\pi}{2}(t_0+t(t_1-t_0)\right)\label{eq:sigma_t_alpha_cosine}
\end{alignat}
Figure \ref{fig:cosine_lambda_t} visualises how the log signal-to-noise ratio $\lambda_t\in[\lambda_{\min},\lambda_{\max}]$ varies with time $t\in[0,1]$ using the $\alpha$-cosine schedule detailed above; Figure \ref{fig:cosine_alpha_sigma} similarly visualises how the values of $\alpha_t$ and $\sigma_t$ vary with time $t\in[0,1]$.

\begin{figure}[htbp]
      \centering
      \begin{tikzpicture}
      \begin{axis}[
            xlabel=$t$,
            ylabel=$\lambda_t$,
            ylabel near ticks,
            xlabel near ticks,
            ylabel style={rotate=-90},
            xmin=0,
            xmax=1,
            ymin=-30,
            ymax=30,
            width=.5\linewidth]
      \addplot[color=red,thick,domain=-0.005:1.005,samples=200]{-2 * ln(tan(deg(pi / 2 * ((2 / pi * rad(atan(exp(-0.5 * 30)))) + x * ((2 / pi * rad(atan(exp(-0.5 * -30)))) - (2 / pi * rad(atan(exp(-0.5 * 30)))))))))};
      \end{axis}
      \end{tikzpicture}
      \caption{Relationship between time $t$ and the log signal-to-noise ratio $\lambda_t$ for the truncated continuous-time $\alpha$-cosine noise schedule $f_\Lambda(t)$ as defined in Equation \ref{eq:f_lambda_alpha_cosine} with $\lambda_{\min}=-30$ and $\lambda_{\max}=30$. The horizontal axis is time $t\in[0,1]$; the vertical axis is $\lambda_t=f_\Lambda(t)\in[\lambda_{\min},\lambda_{\max}]=[-30, 30]$.}
      \label{fig:cosine_lambda_t}
\end{figure}

\begin{figure}[htbp]
      \centering
      \begin{subfigure}{0.49\textwidth}
            \begin{tikzpicture}
            \begin{axis}[
                  xlabel=$t$,
                  ylabel=$\alpha_t$,
                  ylabel near ticks,
                  xlabel near ticks,
                  ylabel style={rotate=-90},
                  xmin=0,
                  xmax=1,
                  ymin=0,
                  ymax=1,
                  width=\linewidth]
            \addplot[color=red,thick,domain=0:1,samples=100]{cos(deg(pi / 2 * ((2 / pi * rad(atan(exp(-0.5 * 30)))) + x * ((2 / pi * rad(atan(exp(-0.5 * -30)))) - (2 / pi * rad(atan(exp(-0.5 * 30))))))))};
            \end{axis}
            \end{tikzpicture}
      \end{subfigure}
      \begin{subfigure}{0.49\textwidth}
            \begin{tikzpicture}
            \begin{axis}[
                  xlabel=$t$,
                  ylabel=$\sigma_t$,
                  ylabel near ticks,
                  xlabel near ticks,
                  ylabel style={rotate=-90},
                  xmin=0,
                  xmax=1,
                  ymin=0,
                  ymax=1,
                  width=\linewidth]
            \addplot[color=red,thick,domain=0:1,samples=100]{sin(deg(pi / 2 * ((2 / pi * rad(atan(exp(-0.5 * 30)))) + x * ((2 / pi * rad(atan(exp(-0.5 * -30)))) - (2 / pi * rad(atan(exp(-0.5 * 30))))))))};
            \end{axis}
            \end{tikzpicture}
      \end{subfigure}
      \caption{Relationship between time $t$ and $\alpha_t$ (left) and $\sigma_t$ (right) for the same truncated continuous-time $\alpha$-cosine noise schedule as that in Figure \ref{fig:cosine_lambda_t}. The horizontal axis is time $t\in[0,1]$; the vertical axis is the value of $\alpha_t$ (left) and $\sigma_t$ (right).}
      \label{fig:cosine_alpha_sigma}
\end{figure}

We can, in theory, use two different noise schedules: one to train the model and another to generate new samples. During training, the noise schedule affects the variance of the gradients \cite{Understanding_Diffusion_Objective_Kingma}. During generation, we typically want to use a noise schedule that optimises the quality of the generated samples. In this work, we use the $\alpha$-cosine schedule for training and generation, as we found it to produce high-quality samples for both. During training, we sample $t\sim\mathcal{U}(0,1)$ uniformly at random, then compute $\lambda=f_\Lambda(t)$, which equates to sampling $\lambda\sim p_\Lambda(\lambda)$, where $p_\Lambda(\lambda)$ is given by:
\begin{align}
      p_\Lambda(\lambda)=\frac{1}{2\pi(t_1-t_0)}\mathrm{sech}\left(\frac{\lambda}{2}\right)
\end{align}
Figure \ref{fig:p_lambda} displays the probability density function $p_\Lambda(\lambda)$.
\begin{figure}[htbp]
      \centering
      \begin{tikzpicture}
      \begin{axis}[
            xlabel=$\lambda$,
            ylabel=$p_\Lambda(\lambda)$,
            ylabel near ticks,
            xlabel near ticks,
            ylabel style={rotate=-90},
            xmin=-30,
            xmax=30,
            ymin=0,
            ymax=0.18,
            width=.5\linewidth]
      \addplot[color=red,thick,domain=-30:30,samples=300]{ (1 / cosh(x/2)) / (2 * pi * (2 / pi * rad(atan(exp(-0.5 * -30)))) - (2 / pi * rad(atan(exp(-0.5 * 30)))))};
      \end{axis}
      \end{tikzpicture}
      \caption{Probability density function $p_\Lambda(\lambda)$ for the same truncated continuous-time $\alpha$-cosine schedule as that in Figure \ref{fig:cosine_lambda_t}. The horizontal axis is the log signal-to-noise ratio $\lambda\in[\lambda_{\min}, \lambda_{\max}]$; the vertical axis is the corresponding probability density $p_\Lambda$.}
      \label{fig:p_lambda}
\end{figure}

\subsection{Reverse-Time Generative Model}
\label{sec:background_diffusion_reverse}

Anderson \cite{Reverse_Time_Diffusion_Anderson} shows that the forward SDE of Equation \ref{eq:forward_sde} is exactly solved by a second diffusion process, running backwards in time and given by the reverse-time SDE:
\begin{align}
      d\mathbf{z}_t=\left[\mathbf{f}(\mathbf{z}_t, t)-g(t)^2\nabla_{\mathbf{z}_t}\log q(\mathbf{z}_t)\right]dt + g(t)d\bar{\mathbf{w}_t}
\end{align}
where $\bar{\mathbf{w}}_t$ is a standard Wiener process when time flows backwards. Let $\mathbf{s}_\theta(\mathbf{z}_t, \lambda_t)$ be a $\lambda_t$-dependent score network \cite{Generative_Modelling_By_Estimating_Gradients_Song} that approximates the score of $q(\mathbf{z}_t)$ such that:
\begin{align}
      \mathbf{s}_\theta(\mathbf{z}_t, \lambda_t)\approx \nabla_{\mathbf{z}_t} \log q(\mathbf{z}_t)\label{eq:score_network}
\end{align}
If we have a perfect score model $\mathbf{s}_\theta(\mathbf{z}_t, \lambda_t)=\nabla_{\mathbf{z}_t}q(\mathbf{z}_t)$, then the reverse-time SDE is exactly:
\begin{align}
      d\mathbf{z}_t=\left[\mathbf{f}(\mathbf{z}_t, t)-g(t)^2\mathbf{s}_\theta(\mathbf{z}_t, \lambda_t)\right]dt + g(t)d\bar{\mathbf{w}_t}
\end{align}
For large enough $\lambda_{\max}$, $\mathbf{z}_0$ is almost noiseless, so learning a model $p_\theta(\mathbf{z}_0)$ is practically equivalent to learning a model $p_\theta(\mathbf{x})$. If $D_{\mathrm{KL}}(q(\mathbf{z}_1)\Vert p_\theta(\mathbf{z}_1))\approx 0$ and $\mathbf{s}_\theta(\mathbf{z}_t,\lambda_t)\approx \nabla_{\mathbf{z}_t}\log q(\mathbf{z}_t)$, then we have a good generative model because $D_{\mathrm{KL}}(q(\mathbf{z}_0,\ldots,\mathbf{z}_1)\Vert p_\theta(\mathbf{z}_0,\ldots,\mathbf{z}_1))\approx 0$, which implies that $D_{\mathrm{KL}}(q(\mathbf{z}_0)\Vert p_\theta(\mathbf{z}_0))\approx 0$. Thus, we can reduce the goal of generative modelling to learning a good score network $\mathbf{s}_\theta(\mathbf{z}_t,\lambda_t)$.

In the broader literature, diffusion models utilise a variety of numerical solvers to provide approximate trajectories of the reverse-time SDE. In this work, we sequentially generate latent variables from $t=1$ and work backwards to $t=0$, over $T$ uniformly-spaced discrete timesteps. More formally, this comprises a hierarchical generative model that defines a joint distribution over latent variables as follows:
\begin{align}
      p_\theta(\mathbf{z}_0,\ldots,\mathbf{z}_1)=p_\theta(\mathbf{z}_1)\prod_{i=1}^T p_\theta(\mathbf{z}_{s(i)}|\mathbf{z}_{t(i)})
\end{align}
where $s(i)=(i - 1)\cdot T^{-1}$ and $t(i)=i\cdot T^{-1}$.  For sufficiently small $\lambda_{\min}$, $\mathbf{z}_1$ contains almost no information about $\mathbf{x}$. As such, there exists a distribution $p_\theta(\mathbf{z}_1)$ such that:
\begin{align}
      D_{\mathrm{KL}}(q(\mathbf{z}_1|\mathbf{x})\Vert p_\theta(\mathbf{z}_1))\approx 0
\end{align}
For variance-preserving diffusion models, as used in this work, we model $p_\theta(\mathbf{z}_1)$ as the multivariate standard Gaussian:
\begin{align}
      p_\theta(\mathbf{z}_1)=\mathcal{N}(\mathbf{z}_1;\mathbf{0}, \mathbf{I})
\end{align}
Once we have sampled $\mathbf{z}_1\sim p_\theta(\mathbf{z}_1)$, we use the discrete-time ancestral sampler \cite{DDPM_Ho} to sequentially generate each latent variable $\mathbf{z}_s$ from $\mathbf{z}_t$ where $0\le s < t \le 1$. This corresponds to a particular discretisation of the reverse-time variance-preserving SDE, as shown by Song et al. \cite{Score_Based_Song}. More formally, from a given latent $\mathbf{z}_t$ we generate $\mathbf{z}_s\sim p_\theta(\mathbf{z}_s|\mathbf{z}_t)$ via:
\begin{align}
      p_\theta(\mathbf{z}_s|\mathbf{z}_t)&=q(\mathbf{z}_s|\mathbf{z}_t,\mathbf{x}=\hat{\mathbf{x}}_\theta(\mathbf{z}_t,\lambda_t))\label{eq:ancestral_sampler}\\
      &=\mathcal{N}\left(\tilde{\boldsymbol\mu}_{s|t}(\mathbf{z}_t,\mathbf{x}=\hat{\mathbf{x}}_\theta(\mathbf{z}_t,\lambda_t)), \tilde{\sigma}_{s|t}\mathbf{I}\right)
\end{align}
where $\hat{\mathbf{x}}_\theta(\mathbf{z}_t,\lambda_t)$ is our denoised estimate of the original data $\mathbf{x}$ given latent $\mathbf{z}_t$ and log signal-to-noise ratio $\lambda_t$, and
\begin{align}
      \tilde{\boldsymbol\mu}_{s|t}(\mathbf{z}_t,\mathbf{x})&=\frac{\alpha_{t|s}\sigma_s^2}{\sigma_t^2}\mathbf{z}_t+\frac{\alpha_s\sigma_{t|s}^2}{\sigma_t^2}\mathbf{x}\\
      \tilde{\sigma}_{s|t}&=\frac{\sigma_{t|s}\sigma_s}{\sigma_t}
\end{align}

\subsection{Parameterisations}
\label{sec:background_diffusion_parameterisations}

Interestingly, in Equation \ref{eq:ancestral_sampler}, we defined our hierarchical reverse-time generative model in terms of a denoiser network $\hat{\mathbf{x}}_\theta(\mathbf{z}_t, \lambda_t)$, while previously reducing the goal of generative modelling to learning a score network $\mathbf{s}_\theta(\mathbf{z}_t,\lambda_t)$. In practice, one of the powerful aspects of diffusion models is that we can freely switch between different parameterisations. For example, we can train a neural network $\mathbf{s}_\theta(\mathbf{z}_t, \lambda_t)$ to predict the score of $\mathbf{z}_t$ and then convert the output to a denoised estimate of $\mathbf{z}_t$, as if we had trained a denoiser network $\mathbf{x}_\theta(\mathbf{z}_t, \lambda_t)$ directly. This reparameterisation property can be exceptionally advantageous.

Training a neural network to predict $\mathbf{x}\approx\hat{\mathbf{x}}_\theta(\mathbf{z}_t, \lambda_t)$ directly is referred to as the $\mathbf{x}$-prediction parameterisation, but is seldom adopted in the broader literature due to sub-optimal sample quality \cite{DDPM_Ho}. Recent diffusion models instead typically adopted different parameterisations, most commonly the $\boldsymbol\epsilon$-prediction parameterisation (see e.g. \cite{DDPM_Ho, Cascaded_Ho, Imagen_Saharia}). In the $\boldsymbol\epsilon$-prediction framework, we instead train a neural network to predict the noise $\boldsymbol\epsilon\approx\hat{\boldsymbol\epsilon}_\theta(\mathbf{z}_t,\lambda_t)$ directly. In practice, the discrepancies in sample quality that arise from alternative parameterisations are due to the corresponding loss functions equating to different implicit weighting functions; we explore this in more detail in Section \ref{sec:background_diffusion_weighted_loss}.

In this work, we employ the $\mathbf{v}$-prediction parameterisation, introduced originally by Salimans and Ho \cite{Progressive_Distillation_Salimans}, and commonly employed in video diffusion models (see e.g. \cite{VDM_Ho, Imagen_Video_Ho}). Though introduced initially to facilitate progressive distillation for faster sampling, we utilise the $\mathbf{v}$-prediction parameterisation in this work for its additional benefits highlighted by Ho et al. \cite{Imagen_Video_Ho}. Namely, faster convergence of sample quality and prevention of temporal colour shifting observed with $\boldsymbol\epsilon$-prediction video diffusion models. Formally, we define $\psi$ as:
\begin{align}
      \psi = \arctan\left(\frac{\sigma_t}{\alpha_t}\right)=\frac{\pi}{2}(t_0+t(t_1-t_0))
\end{align}
For a given datapoint $\mathbf{x}$, the velocity $\mathbf{v}$ of latent $\mathbf{z}_t$ is given by:
\begin{align}
      \mathbf{v}=\frac{d\mathbf{z}_t}{d\psi}&=\cos(\psi)\boldsymbol\epsilon-\sin(\psi)\mathbf{x}\\
      &=\alpha_t\boldsymbol\epsilon -\sigma_t\mathbf{x}
\end{align}
where $\boldsymbol\epsilon\sim\mathcal{N}(\mathbf{0}, \mathbf{I})$ is multivariate standard Gaussian noise. We train our neural network $\hat{\mathbf{v}}_\theta(\mathbf{z}_t,\lambda_t)$ to predict $\mathbf{v}$ by minimising the following loss function, defined per datapoint $\mathbf{x}$ as:
\begin{align}
      \mathbb{E}_{\lambda\sim p_\Lambda(\lambda),\boldsymbol\epsilon\sim\mathcal{N}(\mathbf{0},\mathbf{I})}\left[\Vert\mathbf{v}-\hat{\mathbf{v}}_\theta(\mathbf{z}_t, \lambda_t)\Vert_2^2\right]\label{eq:v_parameterisation_loss}
\end{align}
We can trivially convert our estimate of the velocity $\hat{\mathbf{v}}_\theta(\mathbf{z}_t,\lambda_t)$ into an estimate of the denoised latent $\hat{\mathbf{x}}_\theta(\mathbf{z}_t,\lambda_t)$, an estimate of the noise $\hat{\boldsymbol\epsilon}_\theta(\mathbf{z}_t,\lambda_t)$, or an estimate of the score $\hat{\mathbf{s}}_\theta(\mathbf{z}_t,\lambda_t)$ due to the following relationships:
\begin{align}
      \mathbf{x}&=\alpha_t\mathbf{z}_t-\sigma_t\mathbf{v}_t\\
      \boldsymbol\epsilon&=\sigma_t\mathbf{z}_t+\alpha_t\mathbf{v}_t\\
      \nabla_{\mathbf{z}_t}q(\mathbf{z}_t)&=-\mathbf{z}_t-\frac{\alpha_t}{\sigma_t}\mathbf{v}_t
\end{align}

% \subsection{Score-Based Interpretation}

% Suppose we have a multivariate Gaussian variable with mean $\boldsymbol\mu$ and covariance $\boldsymbol\Sigma$:
% \begin{align}
%       \mathbf{z}\sim p(\mathbf{z})=\mathcal{N}(\mathbf{z}; \boldsymbol\mu_{\mathbf{z}}, \boldsymbol\Sigma_{\mathbf{z}})
% \end{align}
% Tweedie's formula states that:
% \begin{align}
% \mathbb{E}\left[\boldsymbol\mu_{\mathbf{z}}|\mathbf{z}\right]=\mathbf{z}+\boldsymbol\Sigma_{\mathbf{z}} \nabla_{\mathbf{z}}\log p(\mathbf{z})
% \end{align}
% As such, for a given latent $\mathbf{z}_t\sim\mathcal{N}(\mathbf{z}_t; \alpha_t\mathbf{x}, \sigma_t^2\mathbf{I})$, the expected value of the mean $\boldsymbol{\mu}_{\mathbf{z}_t}$ given $\mathbf{z}_t$ is given by:
% \begin{align}
%       \mathbb{E}\left[\boldsymbol\mu_{\mathbf{z}_t}|\mathbf{z}_t\right]=\mathbf{z}_t+\sigma_t^2\nabla_{\mathbf{z}_t}\log q(\mathbf{z}_t)
% \end{align}
% From Equation \ref{eq:q_z_t_given_x}, we have $\boldsymbol\mu_{\mathbf{z}_t}=\alpha_t\mathbf{x}$. Thus, we can reformulate the score of $q(\mathbf{z}_t)$ in terms of $\mathbf{z}_t$ and $\mathbf{x}$ as:
% \begin{align}
%       \alpha_t\mathbf{x}=\mathbf{z}_t + \sigma_t^2\nabla_{\mathbf{z}_t}\log q(\mathbf{z}_t)
% \end{align}

\subsection{3D U-Net}
\label{sec:background_unet}

In this work, our $\mathbf{v}$-prediction model $\mathbf{v}_\theta(\mathbf{z}_t, \lambda_t)$ uses the 3D U-Net architecture from \cite{VDM_Ho}. The 3D U-Net architecture is an extension of the 2D U-Net \cite{Ronneberger_U-Net, Salimans_PixelCNN}, the standard architecture employed in recent work on image modelling. It comprises a spatial downsampling pass followed by a spatial upsampling pass with skip connections to the downsampling pass activations. The network contains layers of space-only 3D convolutional residual blocks \cite{VDM_Ho}, with each block followed by a spatial attention block \cite{Vaswani_Attention_is_All_You_Need, Wang_Non-Local_Neural_Networks, Chen_PixelSNAIL}, which treats the temporal axis as a batch axis. A temporal attention block follows each spatial attention block, performing attention over the temporal axis and treating the two spatial axes as batch axes. This form of factorised space-time attention is known for its computational efficiency \cite{Arnab_ViViT, Bertasius_Is_Space-Time_Attention_All_You_Need, Ho_Axial_Attention_in_Multidimensional_Transformers}.

\subsection{ELBO for Diffusion Models}
\label{sec:background_diffusion_elbo}

We can interpret the variance-preserving diffusion model used in this work as an MHVAE with several additional restrictions. Firstly, the dimensionality of each latent $\mathbf{z}_t$ equals the dimensionality of the observed variable. Secondly, we have pre-defined $q(\mathbf{z}_t|\mathbf{z}_s)$ where $0\le s<t\le 1$ as a Gaussian diffusion process with no learnable inference parameters. Finally, the marginal distribution of the final latent $q(\mathbf{z}_1)$ is approximately the multivariate standard Gaussian $\mathcal{N}(\mathbf{0}, \mathbf{I})$, and thus holds effectively no information about the observed variable $\mathbf{x}$. VAEs and MHVAEs do not typically have these restrictions. Nonetheless, much like VAEs and MHVAEs, we can optimise the generative parameters $\theta$ of diffusion models by minimising the ELBO loss. As a notable example, Sohl-Dickstein et al. \cite{Deep_Unsupervised_Learning_Sohl-Dickstein} optimised the original discrete-time diffusion model via the ELBO loss. 

For a given datapoint $\mathbf{x}$, we define $\mathcal{L}_\Lambda(\lambda)$ as the KL divergence of $q(\mathbf{z}_t,\ldots,\mathbf{z}_1|\mathbf{x})$ from $p_\theta(\mathbf{z}_t,\ldots,\mathbf{z}_1)$ for a subset of timesteps from $t=f_\Lambda^{-1}(\lambda)$ to $1$ for datapoint $\mathbf{x}$:
\begin{align}
      \mathcal{L}_\Lambda(\lambda)=D_{\mathrm{KL}}(q(\mathbf{z}_t,\ldots,\mathbf{z}_1|\mathbf{x})\Vert p_\theta(\mathbf{z}_t,\ldots,\mathbf{z}_1))
\end{align}
Notably, $\mathcal{L}_\Lambda(\lambda)$ equates to $\mathcal{L}_T(t)$ defined in Equation \ref{eq:dkl_t} under a simple change of variable:
\begin{align}
      \mathcal{L}_\Lambda(\lambda)=\mathcal{L}_T(t=f_\Lambda^{-1}(\lambda))
\end{align}
Similarly, we can reformulate the ELBO loss for a continuous-time MHVAE given in Equation \ref{eq:elbo_mhvae} to provide the ELBO loss in terms of the log signal-to-noise ratio $\lambda$; it is given per datapoint $\mathbf{x}$ by:
\begin{align}
      \mathcal{L}_{\mathrm{ELBO}}(\mathbf{x})&=\mathbb{E}_{\mathbf{z}_0\sim q(\mathbf{z}_0,\mathbf{x})}\left[-\log p_\theta(\mathbf{x}|\mathbf{z}_0)\right]+\mathcal{L}_\Lambda(\lambda_{\max})\\
      &=\underbrace{\mathbb{E}_{\mathbf{z}_0\sim q(\mathbf{z}_0,\mathbf{x})}\left[-\log p_\theta(\mathbf{x}|\mathbf{z}_0)\right]}_{\text{Reconstruction Loss}}+\underbrace{\mathcal{L}_\Lambda(\lambda_{\min})}_{\text{Prior Loss}}+\int_{\lambda_{\min}}^{\lambda_{\max}}\mathcal{L}_\Lambda'(\lambda)d\lambda\label{eq:diffusion_elbo}
\end{align}
With sufficiently large $\lambda_{\max}$, the reconstruction loss is approximately zero since we can almost perfectly reconstruct $\mathbf{x}$ from $\mathbf{z}_0$---this is particularly true for discrete $\mathbf{x}$. Mathematically, as $\lambda_{\max}\to\infty$, we have:
\begin{align}
      \lim_{\lambda_{\max}\to\infty}q(\mathbf{z}_0|\mathbf{x})=\delta(\mathbf{z}_0-\mathbf{x})
\end{align}
where $\delta$ is the Dirac delta distribution. Similarly, with sufficiently small $\lambda_{\min}$, the prior loss is approximately zero; as $\lambda_{\min}\to-\infty$, we have:
\begin{align}
      \lim_{\lambda_{\min}\to -\infty} q(\mathbf{z}_1|\mathbf{x})&=\mathcal{N}(\mathbf{0}, \mathbf{I})=p_\theta(\mathbf{z}_1)
\end{align}
so the KL divergence prior loss term likewise approaches zero.

In Appendix C of \cite{Understanding_Diffusion_Objective_Kingma}, Kingma and Gao showed that $\mathcal{L}_\Lambda'(\lambda)$---which, with a slight abuse of terminology, they refer to as the \textit{time derivative}---simplifies to a remarkable degree:
\begin{align}
      \mathcal{L}_{\Lambda}'(\lambda)=\frac{d}{d\lambda}\mathcal{L}_\Lambda(\lambda)=\frac{1}{2}\mathbb{E}_{\boldsymbol\epsilon\sim\mathcal{N}(\mathbf{0}, \mathbf{I})}\left[\Vert \boldsymbol\epsilon -\hat{\boldsymbol\epsilon}_\theta(\mathbf{z}_t,\lambda_t)\Vert_2^2\right]\label{eq:time_derivative}
\end{align} 

\subsection{Weighted Loss}
\label{sec:background_diffusion_weighted_loss}

Most diffusion models in the broader literature---including state-of-the-art models---do not optimise their parameters $\theta$ via minimisation of the ELBO loss. In practice, the various objectives used are all special cases of a \textit{weighted loss} \cite{Understanding_Diffusion_Objective_Kingma}, which is defined per datapoint $\mathbf{x}$ as:
\begin{align}
      \mathcal{L}_{\mathrm{WL}}&=w(\lambda_{\min})\mathcal{L}_\Lambda(\lambda_{\min})+\int_{\lambda_{\min}}^{\lambda_{\max}}w(\lambda)\mathcal{L}_\Lambda'(\lambda)d\lambda\label{eq:weighted_loss}
\end{align}
where $w(\lambda)$ is a weighting function. Note that, assuming the reconstruction loss is approximately zero, the ELBO loss given in Equation \ref{eq:diffusion_elbo} is a special case of the weighted loss $\mathcal{L}_{\mathrm{WL}}$ with $w(\lambda) = 1$. Substituting the form of $\mathcal{L}'_\Lambda(\lambda)$ given in Equation \ref{eq:time_derivative} yields the following form for the weighted loss:
\begin{align}
      \mathcal{L}_{\mathrm{WL}}&=w(\lambda_{\min})\mathcal{L}_\Lambda(\lambda_{\min})+\frac{1}{2}\int_{\lambda_{\min}}^{\lambda_{\max}}w(\lambda)\mathbb{E}_{\boldsymbol\epsilon\sim\mathcal{N}(\mathbf{0},\mathbf{I})}\left[\Vert\boldsymbol\epsilon-\hat{\boldsymbol\epsilon}_\theta(\mathbf{z}_t,\lambda)\Vert_2^2\right]d\lambda
\end{align}
This form provides several useful insights. Since the first term---the weighted prior loss---contains no learnable parameters, minimisation of the weighted loss $\mathcal{L}_{\mathrm{WL}}$ equates to minimisation of the intractable integral. In practice, we minimise the integral via an importance-weighted Monte Carlo integrator:
\begin{align}
      \int_{\lambda_{\min}}^{\lambda_{\max}}w(\lambda)\mathbb{E}_{\boldsymbol\epsilon\sim\mathcal{N}(\mathbf{0},\mathbf{I})}\left[\Vert\boldsymbol\epsilon-\hat{\boldsymbol\epsilon}_\theta(\mathbf{z}_t,\lambda_t)\Vert_2^2\right]d\lambda
      &=\mathbb{E}_{\lambda\sim p_\Lambda(\lambda),\boldsymbol\epsilon\sim\mathcal{N}(\mathbf{0}, \mathbf{I})}\left[\frac{w(\lambda)}{p_\Lambda(\lambda)}\Vert \boldsymbol\epsilon-\hat{\boldsymbol\epsilon}_\theta(\mathbf{z}_t,\lambda)\Vert_2^2\right]\\
      &\simeq \frac{w(\lambda)}{p_\Lambda(\lambda)}\Vert \boldsymbol\epsilon-\hat{\boldsymbol\epsilon}_\theta(\mathbf{z}_t,\lambda)\Vert_2^2
\end{align}
Notable further analysis by Kingma and Gao \cite{Understanding_Diffusion_Objective_Kingma} shows that the weighted loss also has a likelihood-based interpretation. Simple integration by parts enables us to write the weighted loss as:
\begin{align}
      \mathcal{L}_{\mathrm{WL}} = w(\lambda_{\max})\mathcal{L}_\Lambda(\lambda_{\max}) + \int_{\lambda_{\min}}^{\lambda_{\max}}-w'(\lambda)\mathcal{L}_\Lambda(\lambda) d\lambda
\end{align}
The likelihood-based interpretation comes from the fact that $\mathcal{L}_\Lambda(\lambda)$ serves as a variational bound on the negative marginal likelihood of the noise-perturbed data $\mathbf{z}_t\sim q(\mathbf{z}_t|\mathbf{x})$:
\begin{align}
      \mathcal{L}_\Lambda(\lambda)&\ge D_{\mathrm{KL}}(q(\mathbf{z}_t|\mathbf{x})\Vert p(\mathbf{z}_t))\\
      &=\mathbb{E}_{\mathbf{z}_t\sim q(\mathbf{z}_t|\mathbf{x})}\left[-\log p(\mathbf{z}_t)\right]+\mathbb{E}_{\mathbf{z}_t\sim q(\mathbf{z}_t|\mathbf{x})}\left[\log q(\mathbf{z}_t|\mathbf{x})\right]
\end{align}
As such, minimisation of $\mathcal{L}_\Lambda(\lambda)$ equates to maximisation of the expected log-likelihood of the noise-perturbed data $\mathbf{z}_t\sim q(\mathbf{z}_t|\mathbf{x})$ with noise level $\lambda$. If the weighting function $w(\lambda)$ is a monotonically decreasing function of $\lambda\in [\lambda_{\min}, \lambda_{\max}]$, then by definition $-w'(\lambda)$ will be positive for all $\lambda\in [\lambda_{\min}, \lambda_{\max}]$. In which case, minimisation of $\mathcal{L}_{\mathrm{WL}}$ itself equates to maximisation of the weighted expected log-likelihood of the noise-perturbed data $\mathbf{z}_t\sim q(\mathbf{z}_t|\mathbf{x})$ with weighting $-w'(\lambda)$. 

Kingma and Gao's \cite{Understanding_Diffusion_Objective_Kingma} analysis directly justifies our use of the $\mathbf{v}$-prediction parameterisation with the $\alpha$-cosine noise schedule. In conjunction, the $\mathbf{v}$-prediction parameterisation loss function given in Equation \ref{eq:v_parameterisation_loss} equates to the weighted loss with:
\begin{align}
      w(\lambda)&=\frac{1}{2\pi(t_1-t_0)}\exp\left(-\frac{\lambda}{2}\right)\\
      -w'(\lambda)&=\frac{1}{4\pi(t_1-t_0)}\exp\left(-\frac{\lambda}{2}\right)
\end{align}
Figure \ref{fig:v_prediction_weighting} shows the weighting function $w(\lambda)$ and the negative of its derivative $-w'(\lambda)$ for the $\mathbf{v}$-parameterisation loss. As evident from the graphs, the weighting function $w(\lambda)$ is a monotonically decreasing function of $\lambda$, and as such $-w'(\lambda)$ is positive for all $\lambda\in [\lambda_{\min}, \lambda_{\max}]$. Therefore, during training, we are maximising a weighted expected log-likelihood of noise-perturbed data $\mathbf{z}_t\sim q(\mathbf{z}_t|\mathbf{x})$ for all $\lambda\in[\lambda_{\min}, \lambda_{\max}]$. In contrast, most diffusion models in the broader literature (see e.g. \cite{DDPM_Ho, IDDPM_Nichol,Imagen_Saharia}) undergo training with non-monotonic weighting functions. In such cases, for noise levels whereby $-w'(\lambda)$ is negative, the weighted loss has a counterintuitive interpretation of minimisation of the weighted expected log-likelihood of the noise-perturbed data $\mathbf{z}_t\sim q(\mathbf{z}_t|\mathbf{x})$.
\begin{figure}[htbp]
      \centering
      \begin{tikzpicture}
            \begin{axis}[
                  xlabel=$\lambda$,
                  ymode = log,
                  xmin=-30,
                  xmax=30,
                  ymin=0.00000001,
                  ymax=1000000,
                  width=.5\linewidth,
                  legend pos=north east,
                  legend style={font=\small},
                  legend cell align={left},
                  ylabel style={rotate=-90},
                  ylabel near ticks,
                  xlabel near ticks
                  ]
                  \addplot[color=red,thick,domain=-30:30,samples=100]{1 / ((2 * pi * (2 / pi * rad(atan(exp(-0.5 * -30)))) - (2 / pi * rad(atan(exp(-0.5 * 30)))))) * exp(-x / 2)};
                  \addlegendentry{$w(\lambda)$}
                  \addplot[color=blue,thick,domain=-30:30,samples=100]{1 / ((4 * pi * (2 / pi * rad(atan(exp(-0.5 * -30)))) - (2 / pi * rad(atan(exp(-0.5 * 30)))))) * exp(-x / 2)};
                  \addlegendentry{$-w'(\lambda)$}
                  \end{axis}
      \end{tikzpicture}
      \caption{Relationship between the log signal-to-noise ratio $\lambda$ and the functions $w(\lambda)$ and $-w'(\lambda)$ for the $\mathbf{v}$-parameterisation with the same truncated continuous-time $\alpha$-cosine schedule as that in Figure \ref{fig:cosine_lambda_t}. The horizontal axis is the log signal-to-noise level $\lambda$; the vertical axis is the value of $w(\lambda)$ and $-w'(\lambda)$; the vertical axis is logarithmic.}
      \label{fig:v_prediction_weighting}
\end{figure}

\subsection{Imputation for Conditional Generation}

In Section \ref{sec:background_conditional}, we introduced the concept of conditional generation. In this work, however, we do not train a conditional model explicitly. Instead, we utilise \textit{reconstruction-guided sampling} \cite{VDM_Ho}: a sophisticated technique that derives a conditional model approximately from an unconditional model. More specifically, reconstruction-guided sampling facilitates the conditional generation of the unknown dimensions of some observed datapoint $\mathbf{x}$ given the known dimensions. Deriving such a conditional model approximately from an unconditional model is advantageous: it enables us to train only a single unconditional model, which we can then flexibly use to facilitate the conditional generation of any unknown subset of dimensions.  In this work, we utilise reconstruction-guided sampling to facilitate three distinct conditional generation tasks: temporal interpolation, forecasting, and autoregressive generation of arbitrarily long samples. 

Reconstruction-guided sampling extends a prior technique known as \textit{imputation}, introduced by Song et al. \cite{Score_Based_Song}. Thus, we first introduce imputation for completeness and to better motivate our use of reconstruction-guided sampling in this work.

We denote by $\Omega(\mathbf{x})$ and $\bar\Omega(\mathbf{x})$ the known and unknown dimensions of some observed datapoint $\mathbf{x}$, respectively. Formally, our goal is to derive the following conditional model without training it explicitly:
\begin{align}
      p_\theta(\bar\Omega(\mathbf{x})|\Omega(\mathbf{x}))
\end{align}
We can write the forward diffusion process for the unknown dimensions as the following SDE:
\begin{align}
      d\bar\Omega(\mathbf{z}_t)=\mathbf{f}(\bar\Omega(\mathbf{z}_t), t) + g(t)d\mathbf{w}_t
\end{align}
Anderson \cite{Reverse_Time_Diffusion_Anderson} shows that the corresponding reverse-time SDE conditioned on the known dimensions $\Omega(\mathbf{x})$ is given by:
\begin{align}
      d\bar\Omega(\mathbf{z}_t)=\left[\mathbf{f}(\bar\Omega(\mathbf{z}_t), t) - g(t)^2\nabla_{\bar\Omega(\mathbf{z}_t)}\log q(\bar\Omega(\mathbf{z}_t)|\Omega(\mathbf{x}))\right]dt + g(t)d \bar{\mathbf{w}}_t\label{eq:recon_reverse_sde}
\end{align}
Although $q(\bar\Omega(\mathbf{z}_t)|\Omega(\mathbf{x}))$ is intractable, we can approximate it as follows:
\begin{align}
      q(\bar\Omega(\mathbf{z}_t)|\Omega(\mathbf{x}))&=\int q(\bar\Omega(\mathbf{z}_t), \Omega(\mathbf{z}_t)|\Omega(\mathbf{x}))d\Omega(\mathbf{z}_t)\\
      &=\int q(\bar\Omega(\mathbf{z}_t)|\Omega(\mathbf{x}), \Omega(\mathbf{z}_t))q(\Omega(\mathbf{z}_t)|\Omega(\mathbf{x})) d\Omega(\mathbf{z}_t)\\
      &=\mathbb{E}_{\Omega(\mathbf{z}_t)\sim q(\Omega(\mathbf{z}_t)|\Omega(\mathbf{x}))}\left[q(\bar\Omega(\mathbf{z}_t)|\Omega(\mathbf{x}), \Omega(\mathbf{z}_t))\right]\\
      &\approx \mathbb{E}_{\Omega(\mathbf{z}_t)\sim q(\Omega(\mathbf{z}_t)|\Omega(\mathbf{x}))}\left[q(\bar\Omega(\mathbf{z}_t)| \Omega(\mathbf{z}_t))\right]\label{eq:imputation_assumption}
\end{align}
Song et al. \cite{Score_Based_Song} argue that the approximation in Equation \ref{eq:imputation_assumption} is appropriate since for small $t$, $\Omega(\mathbf{x})$ is almost the same as $\Omega(\mathbf{z}_t)$; and for larger $t$, $\Omega(\mathbf{x})$ is further away from $\bar\Omega(\mathbf{z}_t)$ in the Markov chain, and thus has a minor impact on $\bar\Omega(\mathbf{z}_t)$. Assuming the approximation holds, we can derive an unbiased estimator of $q(\bar\Omega(\mathbf{z}_t)|\Omega(\mathbf{x}))$ as:
\begin{align}
      q(\bar\Omega(\mathbf{z}_t)|\Omega(\mathbf{x})) \approx \mathbb{E}_{\Omega(\mathbf{z}_t)\sim q(\Omega(\mathbf{z}_t)|\Omega(\mathbf{x}))}\left[q(\bar\Omega(\mathbf{z}_t)| \Omega(\mathbf{z}_t))\right] \simeq q(\bar\Omega(\mathbf{z}_t)| \Omega(\mathbf{z}_t))
\end{align}
The score of the natural logarithm of the unbiased estimator is given by:
\begin{align}
      \nabla_{\bar\Omega(\mathbf{z}_t)} \log q(\bar\Omega(\mathbf{z}_t)| \Omega(\mathbf{z}_t))&=\nabla_{\bar\Omega(\mathbf{z}_t)}\left[\log q(\bar\Omega(\mathbf{z}_t), \Omega(\mathbf{z}_t)) - \log q(\Omega(\mathbf{z}_t))\right]\\
      &=\nabla_{\bar\Omega(\mathbf{z}_t)} \log q(\bar\Omega(\mathbf{z}_t), \Omega(\mathbf{z}_t))\\
      &=\nabla_{\bar\Omega(\mathbf{z}_t)} \log q([\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)])
\end{align}
where $[\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)]$ denotes a vector such that:
\begin{align}
      \Omega([\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)]) = \Omega(\mathbf{z}_t)\\
      \bar\Omega([\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)]) = \bar\Omega(\mathbf{z}_t)
\end{align}
Thus, assuming the assumption given in Equation \ref{eq:imputation_assumption} holds, we can consequently approximate the reverse-time SDE conditioned on $\Omega(\mathbf{x})$ given in Equation \ref{eq:recon_reverse_sde} as follows:
\begin{align}
      d\bar\Omega(\mathbf{z}_t)=\left[\mathbf{f}(\bar\Omega(\mathbf{z}_t), t) - g(t)^2\nabla_{\bar\Omega(\mathbf{z}_t)}\log q([\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)])\right]dt + g(t)d \bar{\mathbf{w}}_t
\end{align}
If we have a perfect score model, $\mathbf{s}_\theta(\mathbf{z}_t, \lambda_t)=\nabla_{\mathbf{z}_t} q(\mathbf{z}_t)$, then the reverse-time SDE is thus given by:
\begin{align}
      d\bar\Omega(\mathbf{z}_t)=\left[\mathbf{f}(\bar\Omega(\mathbf{z}_t), t) - g(t)^2 \mathbf{s}_\theta([\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)], \lambda_t)\right]dt + g(t)d \bar{\mathbf{w}}_t\label{eq:imputation_reverse_sde}
\end{align}
To provide a more intuitive link between Equation \ref{eq:imputation_reverse_sde} and the generative procedure in Section \ref{sec:background_diffusion_reverse}, we also define the imputation method as a conditional denoiser $\hat{\mathbf{x}}^{\mathrm{C}}_\theta(\mathbf{z}_t, \lambda_t, \Omega(\mathbf{x}))$, which takes the known dimensions of $\mathbf{x}$ as input:
\begin{align}
      \hat{\mathbf{x}}^{\mathrm{C}}_\theta(\mathbf{z}_t, \lambda_t, \Omega(\mathbf{x}))=\bar\Omega\left(\hat{\mathbf{x}}_\theta([\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)], \lambda_t )\right)
\end{align}
Thus, the imputation method for conditional generation yields only a slight adjustment to the generative procedure defined in Section \ref{sec:background_diffusion_reverse}. Namely, at each step of the discrete-time ancestral sampler, we replace the dimensions of $\mathbf{z}_t$ corresponding to the known dimensions of $\mathbf{x}$ with an exact sample from the forward process: $\Omega(\mathbf{z}_t)\sim q(\Omega(\mathbf{z}_t)|\Omega(\mathbf{x}))$.

\subsection{Reconstruction-Guided Sampling for Conditional Generation}
\label{sec:background_diffusion_reconstruction_guided_sampling}

Ho et al. \cite{VDM_Ho} showed that the imputation process produces incoherent samples when applied to video diffusion models. Namely, although a given $\bar\Omega(\mathbf{x})$ will often appear reasonable in isolation, it will often not be coherent with $\Omega(\mathbf{x})$. This incoherency is likely because the assumption in Equation \ref{eq:imputation_assumption} does not hold for all $t\in[0,1]$. Avoiding the assumption, we instead construct an unbiased estimator for $q(\bar\Omega(\mathbf{z}_t|\Omega(\mathbf{x})))$ as:
\begin{align}
      q(\bar\Omega(\mathbf{z}_t)|\Omega(\mathbf{x}))&=\mathbb{E}_{\Omega(\mathbf{z}_t)\sim q(\Omega(\mathbf{z}_t)|\Omega(\mathbf{x}))}\left[q(\bar\Omega(\mathbf{z}_t)|\Omega(\mathbf{x}), \Omega(\mathbf{z}_t))\right] \simeq q(\bar\Omega(\mathbf{z}_t)|\Omega(\mathbf{x}), \Omega(\mathbf{z}_t))
\end{align}
The score of the natural logarithm of the unbiased estimator is given by:
\begin{align}
      \nabla_{\bar\Omega(\mathbf{z}_t)} \log q(\bar\Omega(\mathbf{z}_t)|\Omega(\mathbf{x}),\Omega(\mathbf{z}_t))&=\nabla_{\bar\Omega(\mathbf{z}_t)} \left[ \log q(\bar\Omega(\mathbf{z}_t), \Omega(\mathbf{x}), \Omega(\mathbf{z}_t))-\log q(\Omega(\mathbf{z}_t),\Omega(\mathbf{x}))\right]\\
      &=\nabla_{\bar\Omega(\mathbf{z}_t)} \log q(\bar\Omega(\mathbf{z}_t), \Omega(\mathbf{x}), \Omega(\mathbf{z}_t))\\
      &=\nabla_{\bar\Omega(\mathbf{z}_t)} \left[\log q(\bar\Omega(\mathbf{z}_t), \Omega(\mathbf{z}_t)) + \log q(\Omega(\mathbf{x})|\bar\Omega(\mathbf{z}_t), \Omega(\mathbf{z}_t))\right]\\
      &=\nabla_{\bar\Omega(\mathbf{z}_t)} \left[ \log q([\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)]) + \log q(\Omega(\mathbf{x})|[\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)])\right]\label{eq:recon_reverse_sde_score}
\end{align}
The $\log q(\Omega(\mathbf{x})|[\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)])$ term in Equation \ref{eq:recon_reverse_sde_score} is missing in the imputation approach. Plugging in this missing term would make conditional sampling exact. However, since the conditional probability is not available in closed form, we must approximate it. Ho et al. \cite{VDM_Ho} proposed to approximate it with a multivariate Gaussian of the form:
\begin{align}
      q(\Omega(\mathbf{x})|[\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)]) \approx \mathcal{N}\left(\Omega(\mathbf{x}); \Omega\left(\hat{\mathbf{x}}_\theta\left([\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)], \lambda_t \right)\right), \left(\frac{\sigma_t^2}{\alpha_t^2}\right)\mathbf{I}\right)
\end{align}
Under this approximation, the $\log q(\Omega(\mathbf{x})|[\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)])$ term is thus itself approximated by:
\begin{align}
      \log q(\Omega(\mathbf{x})|[\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)])\approx-\frac{\alpha_t^2}{2\sigma_t^2} \left\Vert \Omega(\mathbf{x}) - \Omega\left(\hat{\mathbf{x}}_\theta\left([\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)], \lambda_t \right)\right)\right\Vert_2^2
\end{align}
Ho et al. \cite{VDM_Ho} interpret the inclusion of this term---absent in the imputation method---as a form of \textit{guidance} based on the model's reconstruction of the conditioning data. They found empirically that---as with other forms of guidance---including a large weighting term $w_r>1$ tends to improve sample quality further. They refer to this technique as \textit{reconstruction-guided sampling}. Formally, assuming we have a perfect score model $\mathbf{s}_\theta(\mathbf{z}_t, \lambda_t)=\nabla_{\mathbf{z}_t} q(\mathbf{z}_t)$, reconstruction-guided sampling derives a conditional model from an unconditional model by approximating the score given in Equation \ref{eq:recon_reverse_sde} by:
\begin{align}
      \nabla_{\bar\Omega(\mathbf{z}_t)}\log q(\bar\Omega(\mathbf{z}_t)|\Omega(\mathbf{x}))&\approx \mathbf{s}_\theta ([\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)], \lambda_t)\\&-\frac{w_r\alpha_t^2}{2\sigma_t^2}\nabla_{\bar\Omega(\mathbf{z}_t)} \left\Vert \Omega(\mathbf{x}) - \Omega\left(\hat{\mathbf{x}}_\theta\left([\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)], \lambda_t \right)\right)\right\Vert_2^2
\end{align}
Writing the reconstruction-guidance method as a conditional denoiser $\hat{\mathbf{x}}^{\mathrm{C}}_\theta(\mathbf{z}_t, \lambda_t, \Omega(\mathbf{x}))$ yields:
\begin{align}
      \hat{\mathbf{x}}^{\mathrm{C}}_\theta(\mathbf{z}_t, \lambda_t, \Omega(\mathbf{x}))=\bar\Omega\left(\hat{\mathbf{x}}_\theta([\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)], \lambda_t )\right) - \frac{w_r\alpha_t}{2}\nabla_{\bar\Omega(\mathbf{z}_t)} \left\Vert \Omega(\mathbf{x}) - \Omega\left(\hat{\mathbf{x}}_\theta\left([\bar\Omega(\mathbf{z}_t); \Omega(\mathbf{z}_t)]\right)\right)\right\Vert_2^2
\end{align}

\chapter{Related Work}
\label{chap:background_climate}

Recent developments in generative artificial intelligence have unveiled new opportunities within the realm of climate science. Researchers are increasingly exploring generative AI techniques to address pressing issues. We can broadly classify a considerable proportion of this research into two main categories. The first encompasses machine-learning-based statistical downscaling: generating high-resolution climate simulations from low-resolution simulations. The second category involves using generative models for nowcasting: forecasting with local detail from the present up to six hours ahead \cite{WMO_Guidelines_Nowcasting}.

\section{Statistical Downscaling}
\label{sec:background_climate_downscaling}

As the world's climate evolves rapidly, the need for reliable simulations based on emission scenarios has become increasingly pressing. Climate simulations provide plausible projections of climate change for different emission pathways. As such, they provide crucial insights for researchers, governments and organisations alike seeking to mitigate the effects of climate change and formulate policies to shape the future of our planet. 

Climate simulations exist on a spectrum of spatial and temporal resolutions. Global climate models (GCMs), situated at the lower-resolution end of the spectrum, provide spatial resolutions of 60--300 km and demand relatively low computational resources. However, GCMs necessitate parameterisation schemes to represent the average effects of convection, as explicit representation on the grid is impossible \cite{MO_CPM}. This simplification serves as a known source of model error with several associated problems, including deficiencies in the daily timing on convection and an inability to represent hourly extremes \cite{Hanel_Hourly_Precipitation_Extremes, Gregersen_Assessing_Future_Climatic_Changes}.

Conversely, convection-permitting models (CPMs), a specialised type of regional climate model (RCM) situated at the high-resolution end of the spectrum, offer spatial resolutions of typically only a few kilometres and thus enable explicit representation of convective storms \cite{MO_CPM}. CPMs employ realistic physical representations of relevant climate processes, providing significant advantages such as a better representation of hourly rainfall characteristics, including extremes, compared to models that run at coarser spatial scales \cite{Kendon_Heavier_Summer_Downpours}. High-resolution simulations of this nature facilitate assessments of future risks for extreme events like localised flash flooding; notably, CPMs have shown a substantial increase in hourly precipitation extremes in the UK's summers, which coarser simulations failed to capture \cite{Kendon_Heavier_Summer_Downpours}. However, the substantial computational cost of CPMs is a barrier to their wider deployment \cite{MO_CPM}.

Machine-learning-based statistical downscaling presents an alternative approach for generating high-resolution simulations with reduced computational costs. These methods utilise machine learning to establish a statistical relationship between lower-resolution climate variables and higher-resolution values. A notable example of such an approach is the work of Doury et al. \cite{Doury_Regional_Climate_Model_Emulator}, who employ a variation of the original U-Net architecture \cite{Ronneberger_U-Net} to emulate an RCM with a 12 km spatial resolution based on GCM inputs for regions in France and Spain. However, deterministic systems like these tend to generate blurry samples \cite{Ravuri_Skillful_Precipitation_Nowcasting} and produce only a single output for each input.

In the domain of stochastic systems, Leinenon et al. \cite{Leinonen_Stochastic_Super-Resolution} apply a generative adversarial network (GAN) \cite{Goodfellow_Generative_Adversarial_Networks} to generate time-evolving high-resolution atmospheric fields from low-resolution input sequences. GANs, however, are prone to mode collapse \cite{Thanh-Tung_Mode_Collapse}, indicating they potentially underestimate the probability of extreme atmospheric events. In contrast, diffusion models better capture the complete data distribution and should not encounter the same issues. Addison et al. \cite{Addison_Machine_Learning_Emulation} present the first application of a diffusion model for climate downscaling, showcasing a machine-learning model capable of emulating CPM precipitation. Their work thus proves the capability of diffusion models to provide cheaper, high-resolution precipitation samples with realistic spatial structures based on low-resolution inputs.

This work, too, employs a diffusion model to generate high-resolution precipitation samples. However, in two significant aspects, our research distinguishes itself from Addison et al.'s \cite{Addison_Machine_Learning_Emulation}. Firstly, while their diffusion model operates on individual daily mean snapshots, we focus on time-evolving hourly mean snapshots, acknowledging the importance of temporal patterns in precipitation and the strong autocorrelation inherent in precipitation data. Daily mean snapshots, as employed by Addison et al., may potentially overlook crucial information such as hourly peaks. These can be important, for example, in the context of flash flooding. Secondly, our research does not concern spatial downscaling; instead, we focus on simply establishing an initial proof of principle for generating realistic time-evolving hourly precipitation sequences. In this respect, much of our work thus concentrates on the unconditional setting.

\section{Nowcasting}

Numerical weather prediction (NWP) systems are crucial to modern weather forecasting; they utilise physical equations to generate accurate and realistic predictions several days ahead. However, these systems encounter substantial challenges in producing high-resolution short-term forecasts owing to prevailing computational limitations \cite{Wilson_Nowcasting_Challenges}. In practice, the major limitation of NWP systems is their operational forecast update cycle, which typically spans several hours; in contrast, atmospheric phenomena typically exhibit lifetimes of tens of minutes \cite{Piece_Nowcasting}. This limitation has significant implications, as nowcasting directly supports the real-world socioeconomic needs of various sectors that rely on weather-dependent decision-making \cite{Wilson_Nowcasting_Challenges}.

Prediction systems typically employ alternative approaches that utilise composite radar observations to address the issue of short lead times. Established probabilistic nowcasting methods (see e.g. \cite{Bowler_STEPS}) instead predict precipitation using the advection equation with a radar source term.

In recent years, researchers have explored stochastic machine-learning-based nowcasting systems that surpass the reliance on the advection equation to improve the quality of nowcasts. The current state-of-the-art generative model for nowcasting is the GAN-based model proposed by Ravuri et al. \cite{Ravuri_Skillful_Precipitation_Nowcasting}. Their GAN provides realistic and spatiotemporally coherent nowcasts with lead times ranging between 5 and 90 minutes.

Although nowcasting is not the central focus of this work, we present preliminary proof-of-principle results for nowcasting using a diffusion model in Section \ref{sec:results_nowcasting}. The results presented are not directly comparable to those of Ravuri et al. \cite{Ravuri_Skillful_Precipitation_Nowcasting}. due to our use of a different dataset and the nowcasting implemented encompassing longer timeframes with a lower temporal resolution. Nonetheless, the results provide a promising initial indication of the potential of diffusion models for nowcasting and serve to encourage future research in this direction. As diffusion models have demonstrated superior performance over GANs in much of the broader literature on generative models (see e.g. \cite{DDPM_Ho, Cascaded_Ho, Imagen_Saharia}), we anticipate this trend will similarly extend to nowcasting.

% -----------------------------------------------------------------------------

\chapter{Experiments and Results}
\label{chap:results}

\section{Dataset}
\label{sec:results_dataset}

\subsection{UKCP18}
\label{sec:results_dataset_ukcp18}

For this study, we employ a dataset derived from the United Kingdom Climate Projections 2018 (UKCP18) \cite{MO_UKCP18_Dataset} collection, the UK Met Office's latest generational of national climate projections. The broader UKCP18 dataset contains simulations encompassing diverse climate components under various Representative Concentration Pathways (RCPs), which are trajectories for greenhouse gas concentration adopted by the Intergovernmental Panel on Climate Change.

Within the extensive UKCP18 collection, we utilise the first ensemble member of the local-scale precipitation simulations with 2.2 km grid spacing and an hourly temporal resolution. These high-resolution convection-permitting simulations possess a resolution sufficient for explicitly representing convective storms \cite{MO_CPM}. Such a high resolution facilitates improved simulation of small-scale atmospheric phenomena, including the influence of mountains, coastlines and urban areas on precipitation patterns. The hourly 2.2 km resolution data covers 1981--2000, 2021--2040 and 2061--2080 and is exclusively available for RCP8.5 \cite{MO_RCP_Guidance}, a scenario where greenhouse gas emissions continue to grow unmitigated.

\subsection{Preprocessing}

As part of a preprocessing stage before training our diffusion model, we addressed memory limitations inherent in modern GPUs by coarsening the spatial resolution by 4x in both directions, resulting in a spatial resolution of 8.8 km. This reduced resolution retains many benefits of high-resolution climate data---such as capturing the influence of local-scale topography on precipitation---while adhering to GPU memory constraints. To further accommodate these limitations, we restrict the spatial range of the dataset, focusing on a $563.2\ \mathrm{km}\times 563.2\ \mathrm{km}$ region centred on Birmingham, UK. This region approximately corresponds to England and Wales. Figure \ref{fig:ukcp18_spatial_means} illustrates the area covered in our study. The significant variation in mean precipitation across different regions suggests that we have retained much spatial structure in the preprocessed dataset influenced by topography and other local-scale factors.

\begin{figure}[htbp]
      \centering
      \includegraphics[width=.5\textwidth]{ukcp18_spatial_means.png}
      \caption{Mean precipitation rate for each $8.8\ \mathrm{km}\times 8.8\ \mathrm{km}$ subarea in our dataset.}
      \label{fig:ukcp18_spatial_means}
\end{figure}

In order to ensure that our neural network operates on consistently scaled inputs during the reverse-time generative process, starting from the multivariate standard Gaussian prior, we additionally scale each input data element to the range $[-1,1]$.

\subsection{Seasonally Stratified Train/Test Split}
\label{sec:results_dataset_train_test}

We adopted a stratified-by-season approach to devise an effective train/test split for our dataset. More specifically, we designated 80\% of the data for training and 20\% for testing, allocating every fifth season to the test set. This approach ensures that the test set encompasses a diverse range of samples---including an equal number of samples from each season and no two seasons from the same year---while preserving adequate independence between the train and test sets.

The rationale behind this stratification strategy stems from the dataset's composition, which features hourly precipitation samples spanning 60 years. Given the substantial similarity between adjacent hourly samples in our dataset, a random split would be unsuitable. Such a split could result in many test samples originating from nearly identical temporal instances as those in the training set, thereby diminishing the independence of the train and test sets. By adopting a seasonal stratification, we enhance the independence between the sets while ensuring a diverse range of samples.

We considered a stratified-by-year split but ultimately rejected it. A few notably wet or dry years could lead to a test set with a distribution that significantly deviates from the train set, resulting in biased model evaluation. The seasonal stratification addresses this concern, achieving an equilibrium between minimising the inclusion of adjacent samples in both sets and guaranteeing significant variety over longer timeframes.

\section{Importance of the Transformation}
\label{sec:results_importance_of_transformation}

\subsection{No Transformation}
\label{sec:results_no_transformation}

One of the primary contributions of this work is demonstrating that a transformation of the input data is critical to the model's performance. Since no directly comparable results exist in the broader literature, we first establish a benchmark by providing results for our model trained without any transformation to the input data; we refer to this model as our \textit{no-transformation model} for brevity.

Notably, the model produced samples with two significant, related issues. First and foremost, the generated samples all contain significant perceptible noise at the lower end of the precipitation scale; Figure \ref{fig:no_transform_sample} depicts an example of this. Additionally, many samples exhibit a baseline shift in precipitation rates; that is, samples generated by the model have a modal precipitation rate significantly higher than those observed in the test set. Most samples in the test set have a modal precipitation rate of approximately zero---indicating typically dry conditions. Conversely, many samples generated by our no-transformation model have a modal precipitation rate significantly higher, with little to no subareas below it. In practice, this indicates at least a trace quantity of precipitation across the entirety of the 563.2\ \text{km} $\times$ 563.2\ \text{km} region for the entire ten hours. Even in isolation, this would be an unnatural scenario and thus should certainly not occur at the frequency we observed. Figure \ref{fig:no_transform_global_shift} depicts a sample exhibiting this baseline shift.

\begin{figure}[htbp]
      \centering
      \begin{subfigure}{\textwidth}
            \includegraphics[width=\linewidth]{no_transform_noisy.png}
            \caption{Noise at the lower end of the precipitation scale}
            \label{fig:no_transform_sample}
      \end{subfigure}
      \begin{subfigure}{\textwidth}
            \includegraphics[width=\linewidth]{no_transform_global_shift.png}
            \caption{Baseline shift in precipitation rate}
            \label{fig:no_transform_global_shift}
      \end{subfigure}
      \caption{Two samples generated via our no-transformation model. The sample depicts hourly precipitation for the same $563.2\ \mathrm{km} \times 563.2\ \mathrm{km}$ region centred on Birmingham, UK, over ten hours. Each grid cell illustrates the mean precipitation rate, measured in millimetres per hour, for an $8.8 \ \mathrm{km} \times 8.8\ \mathrm{km}$ subarea. The top sample exhibits significant noise at the lower end of the precipitation scale, while the bottom sample exhibits a baseline shift in precipitation rate.}
\end{figure}

To motivate these phenomena beyond individual examples, Figure \ref{fig:no_transform_histogram_low} depicts the distribution of precipitation rates of our generated samples compared to those in our test set at the lower end of the scale (i.e. less than 0.3 millimetres per hour). As can be seen, below approximately 0.2 millimetres per hour, the distribution of precipitation rates in our generated samples significantly deviates from that of the test set. While precipitation of this scale equates only to trace amounts, it is still non-negligible. Thus, using the generated samples in real-world contexts---such as hydrological studies---may present significant challenges.

\begin{figure}[htbp]
      \centering
      \begin{subfigure}{0.49\textwidth}
            \includegraphics[width=\linewidth]{no_transform_histogram_low.png}
            \caption{Below 0.3 millimetres per hour}
            \label{fig:no_transform_histogram_low}
      \end{subfigure}
      \begin{subfigure}{0.49\textwidth}
            \includegraphics[width=\linewidth]{no_transform_histogram.png}
            \caption{Full range}
            \label{fig:no_transform_histogram_high}
      \end{subfigure}
      \caption{Distribution of individual precipitation intensities in samples generated via our no-transformation model and the test set. The horizontal axis is the precipitation rate, measured in millimetres per hour; the vertical axis is frequency density. The vertical axis is scaled logarithmically. The left graph depicts the distribution of precipitation rates below 0.3 millimetres per hour, while the right graph depicts the full distribution.}
      \label{fig:no_transform_histogram}
\end{figure}

We can attribute this deviation to the two aforementioned issues but cannot pinpoint the underlying cause. We hypothesise that there are multiple contributory factors. Firstly, our score model $\mathbf{s}_\theta(\mathbf{z}_t, \lambda_t)$ is not perfect; in other words, there will exist $\mathbf{z}_t$ such that $\mathbf{s}_\theta(\mathbf{z}_t, \lambda_t)$ does not serve as a good approximation for the true score $\nabla_{\mathbf{z}_t}  \log q(\mathbf{z}_t)$. As such, by traversing the reverse-time SDE via the score model $\mathbf{s}_\theta(\mathbf{z}_t,\lambda_t)$, our reverse-time generative process will frequently not adjust the latent $\mathbf{z}_t$ in the optimal direction to maximise the log-likelihood. Furthermore, since we can only approximate the reverse-time SDE, the discretised numerical solver introduces errors itself---this would be the case even if we had a perfect score model. We speculate that the errors introduced by these two contributory factors manifest as the noise at the lower end of the precipitation scale and the baseline shift in precipitation rate.

Noise of the observed magnitude creates unique challenges for diffusion models generating precipitation data---challenges that do not present as significant an issue in the more common domain of image generation. There are two primary reasons for this. First and foremost, the distribution of precipitation rates in our data is far more skewed than the distribution of colours in image data. This skew is evident in Figure \ref{fig:no_transform_histogram_high}, which contains the full distribution of precipitation rates in our test set from UKCP18. 83\% of the cells in the test set are of a precipitation rate lower than 0.01 millimetres per hour; to put this into perspective, the highest precipitation rate in our test set is approximately 60 millimetres per hour. As a direct result of this extreme distribution, even relatively small amounts of noise at the lower end of the scale or minute inaccuracies in the reverse-time generative model can significantly impact the quality of the generated samples. The second challenge that generating precipitation data presents in contrast to image data is that precipitation is a continuous variable, in contrast to the discrete values that comprise each colour channel in an image. Thus, a final discretisation step at the end of the generative process for images eliminates much of the noise. We cannot take advantage of this approach for precipitation data. In the context of Figure \ref{fig:no_transform_sample} wherein the significant deviation from the true distribution is evident below the 0.2 millimetres per hour threshold, this constitutes approximately 0.2\% of our output space. If this were an image with 256 discrete values per colour channel, this relative amount of the output space represents less than a single discrete value. Thus, a final discretisation step would eliminate the problem almost entirely.

Moving our attention beyond the lower extremity of the precipitation scale, Figure \ref{fig:no_transform_histogram_high} illustrates the distribution of individual intensities within the samples generated by our model, contrasting them with those from the test set. The model demonstrates merit in capturing the overall shape of the true distribution. This similarity suggests that the model has a reasonable degree of success in learning the overall frequency of precipitation of varying intensity levels. However, it is evident that as we progress to more intense precipitation levels, the frequency discrepancy between the generated samples and the test set becomes more pronounced, suggesting a limitation in the model's ability to generate extreme precipitation sufficiently frequently.

To gain a more detailed understanding of the model's performance in a similar respect, we employ a quantile-quantile (QQ) plot, which offers a complementary perspective to the histogram by comparing the quantiles of the generated samples against the quantiles of the test set. QQ plots are particularly useful for detecting deviations in the distribution. From the QQ plot in Figure \ref{fig:no_transform_qq}, it is evident that for a given intensity across most of the precipitation range, our model underestimates the frequency of all precipitation less than that intensity. There is typically a 25\% discrepancy between the value of any given quantile in the test set and its corresponding quantile in the generated samples.

\begin{figure}[htbp]
      \centering
      \includegraphics[width=\textwidth]{no_transform_qq.png}
      \caption{QQ plot comparing the distribution of individual precipitation intensities in samples generated via our no-transformation model with the test set. Quantiles plotted are $\{1 - 10^{-n_1} + n_2 \cdot 10^{-n_1 - 1}\mid n_1,n_2\in \mathbb{N}, 1 \le n_1 \le 6, 1 \le n_2 \le 9\}$. The black line is the reference line, indicating where the quantiles of the generated samples would lie if they were equal to the quantiles of the test set.}
      \label{fig:no_transform_qq}
\end{figure}

Importantly, we observe a notable duality in the model's shortcomings across the precipitation spectrum. Below approximately 0.2 millimetres per hour, the model introduces excessive noise, resulting in an overrepresentation of precipitation of this region in the generated samples. In contrast, the model underpredicts quantiles by about 25\% at higher intensities. The quantiles only align where the overrepresented and underrepresented regions intersect. At this point, the adverse effects of the two issues cancel each other out. This dual issue underscores the challenges the model faces in accurately representing the true distribution of precipitation intensities, which could present potential problems in real-world applications.

Evaluating our model goes beyond analysing the distribution of individual cells' values; it is essential to determine the extent to which our model has learnt the geographical structure of the true precipitation distribution across England and Wales. Ideally, our model must capture regional nuances influenced by topography and local climate patterns. For example, Wales experiences more precipitation on average than England, as the former is more mountainous. Accurate representation of this spatial structure is vital for reliable predictions and well-informed decision-making in agriculture, flood management and infrastructure development. To evaluate the effectiveness of our model in capturing the correct amount of precipitation in different subareas, we employ mean-normalised bias plots as an assessment tool. We calculate mean-normalised bias by subtracting the target mean from the sample mean and dividing the result by the target mean. Figure \ref{fig:no_transform_bias} depicts the mean-normalised bias for each $8.8\ \mathrm{km}\times8.8\ \mathrm{km}$ subarea. There is a weak negative correlation between mean precipitation and mean-normalised bias with a coefficient of determination of 0.31---the samples generated via the model typically have lower precipitation in areas with higher mean precipitation in the test set. Figure \ref{fig:ukcp18_spatial_means} shows that Wales, North West England and South West England broadly have the highest mean precipitation; these regions directly correspond to the regions with the lowest mean-normalised bias in Figure \ref{fig:no_transform_bias}.

\begin{figure}[htbp]
      \centering
      \includegraphics[width=.5\textwidth]{no_transform_bias.png}
      \caption{Mean-normalised bias at each cell representing the same $8.8\ \mathrm{km}\times 8.8\ \mathrm{km}$ geographical area in the samples generated via our no-transformation model.}
      \label{fig:no_transform_bias}
\end{figure}

We must also assess how successfully our model has learnt the true distribution's underlying spatial and temporal structure. This analysis is crucial: theoretically, we could trivially train a model to generate pure noise whereby the distribution of individual cells' values perfectly matches that of the test set for each $8.8\ \mathrm{km}\times 8.8\ \mathrm{km}$ subarea. While an extreme example, this motivates the necessity of ensuring our generated samples also capture the structure and characteristics of the true distribution. To assess the degree to which this is the case, we employ power spectral density (PSD) graphs, which depict a signal's power distribution. In general terms, a PSD graph provides information on the distribution of frequencies present in a signal. In this work, we employ two different PSD graphs: spatial PSD graphs for individual one-hour snapshots of the entire $563.2\ \mathrm{km}\times 563.2\ \mathrm{km}$ region; and temporal PSD graphs for multiple consecutive one-hour snapshots of a single $8.8\ \mathrm{km}\times 8.8\ \mathrm{km}$ subarea. Our interpretation of a PSD graph depends on the nature of the signal. For spatial PSD graphs, greater power at higher spatial frequencies reveals sharp boundaries between areas with and without precipitation, likely indicating the presence of localised showers. On the other hand, greater power at lower spatial frequencies points to smooth variations in precipitation intensity, suggesting a sizeable frontal system. For temporal PSD graphs, greater power at higher temporal frequencies reveals rapid fluctuations in precipitation, indicating the presence of briefer precipitation events such as convective showers. Conversely, greater power at lower temporal frequencies suggests stabler events---potentially a continuous dry spell. 

From Figure \ref{fig:no_transform_psd}, it is evident that the samples in the test set contain more power at both lower spatial and temporal frequencies than at higher temporal and spatial frequencies, on average. The samples generated via our no-transformation model follow a similar trend in both cases, as indicated by the similar shapes of the PSD graphs. We can interpret this as the model having broadly learnt the true distribution's underlying spatial and temporal structure. In other words, the model has broadly learnt the relative frequency of precipitation events at different spatial and temporal scales, from short localised showers to long-lasting frontal systems. However, the samples generated via our model contain less power than those in the test set at all scales.

\begin{figure}[htbp]
      \centering
      \begin{subfigure}{0.49\textwidth}
            \includegraphics[width=\linewidth]{no_transform_psd_spatial.png}
            \caption{Spatial Dimensions}
      \end{subfigure}
      \begin{subfigure}{0.49\textwidth}
            \includegraphics[width=\linewidth]{no_transform_psd_temporal.png}
            \caption{Temporal Dimension}
      \end{subfigure}
      \caption{Power spectral density (PSD) graphs for samples generated via our no-transformation model and the test set. The horizontal axis is the number of waves, denoted $k$; the vertical axis is the mean power across all samples for a given $k$, denoted $P(k)$. Both axes are logarithmic. The left graph is for the two spatial dimensions, and the right graph is for the temporal dimension.}
      \label{fig:no_transform_psd}
\end{figure}

\subsection{Square-Root Transformation}
\label{sec:results_square_root}

In the previous section, we introduced baseline results for our model trained without any transformation applied to the input data. In this section, we build upon this foundation by presenting results for a model employing a square-root transformation to the input, which we henceforth refer to as our \textit{square-root-transformation model} for brevity. The results showcased herein provide compelling evidence that implementing a suitable transformation can significantly enhance the performance of a diffusion model.

Foremost, applying the square-root transformation to the input data effectively addressed the two primary concerns observed in the samples generated by our no-transformation model. Specifically, it eliminated the discernible noise at the lower end of the precipitation scale and averted the unnatural baseline shift in precipitation rates. The improvement is clearly illustrated in Figure \ref{fig:no_transform_vs_sqrt_histogram_low}. Notably, the deviation from the test distribution shape below 0.2 millimetres per hour---observed in our no-transformation model---is absent in samples generated by our square-root-transformation model, exemplifying the effectiveness of incorporating an appropriate transformation during the model training process.

\begin{figure}[htbp]
      \centering
      \begin{subfigure}{.49\textwidth}
            \includegraphics[width=\linewidth]{no_transform_vs_sqrt_histogram_low.png}
            \caption{Below 0.3 millimetres per hour}
            \label{fig:no_transform_vs_sqrt_histogram_low}
      \end{subfigure}
      \begin{subfigure}{.49\textwidth}
            \includegraphics[width=\linewidth]{no_transform_vs_sqrt_histogram.png}
            \caption{Full range}
            \label{fig:no_transform_vs_sqrt_histogram_full}
      \end{subfigure}
      \caption{Distribution of individual precipitation intensities in samples generated via our square-root-transformation model, samples generated via our no-transformation model and the test set. The format of each graph is the same as Figure \ref{fig:no_transform_histogram}}.
      \label{fig:no_transform_vs_sqrt_histogram}
\end{figure}

We hypothesise that the improvement is due to the transformation allocating a more significant portion of the output space $[-1, 1]$ to the lower end of the precipitation scale. Without transformation, the input data is scaled linearly to the range $[-1, 1]$, resulting in the region below 0.2 millimetres per hour occupying only about 0.2\% of the output space. In contrast, the square-root transformation involves computing the square root of each input data element before applying the same linear scaling; consequently, the region below 0.2 millimetres per hour occupies approximately 5\% of the output space, representing a 20-fold increase. We cannot conclusively determine why allocating a more significant portion of the output space to the same region resolves the aforementioned issues. We recommend this as an investigation for future work.

Applying the square-root transformation not only addresses the two previously mentioned issues but also enhances the overall quality of our samples by most measures. As evident in Figure \ref{fig:no_transform_vs_sqrt_histogram_full}, up to approximately 12 millimetres per hour, the frequency of precipitation intensity in 1 millimetre per hour intervals more closely aligns with the test set's distribution compared to samples generated via our no-transformation model. We observe from the QQ plot in Figure \ref{fig:no_transform_vs_sqrt_qq} that this represents approximately 99.99\% of all precipitation intensities in the test set. Beyond this range---encompassing the most intense 0.01\% of precipitation---the dominance of either model is less discernible.

\begin{figure}[htbp]
      \centering
      \includegraphics[width=\textwidth]{no_transform_vs_sqrt_qq.png}
      \caption{QQ plot comparing the distribution of individual cells' values in samples generated by our square-root transformed model to samples generated by our untransformed model and the UKCP18 test set. The format is the same as Figure \ref{fig:no_transform_qq}.}
      \label{fig:no_transform_vs_sqrt_qq}
\end{figure}

Figure \ref{fig:sqrt_bias} depicts the mean-normalised bias for each $8.8\ \mathrm{km}\times 8.8\ \mathrm{km}$ subarea in samples generated via our square-root-transformation model. Compared to the mean-normalised bias for our no-transformation model, given in Figure \ref{fig:no_transform_bias}, the bias is worse for most subareas. However, we argue that the relatively good mean-normalised bias of the no-transformation model is an artefact resulting from the two aforementioned issues at the lower end of the precipitation spectrum. These issues contribute to a reduced probability of the model generating precipitation rates of approximately zero, consequently inducing an artificial increase in the mean precipitation rate. As such, we argue that the relatively severe bias in our square-root-transformation model does not represent an actual regression in performance. Notably, when employing the square-root transformation, we observe no correlation with our no-transformation model in the mean-normalised bias across different subareas, indicating that the choice of transformation can influence the spatial distribution of the bias. Unlike our no-transformation model, our square-root-transformation model exhibits severe mean-normalised bias across Central England, East of England, London, and South East England.

\begin{figure}[htbp]
      \centering
      \includegraphics[width=.5\textwidth]{sqrt_bias.png}
      \caption{Mean-normalised bias at each cell representing the same $8.8\ \mathrm{km}\times 8.8\ \mathrm{km}$ geographical area in the samples generated by our square-root-transformation model.}
      \label{fig:sqrt_bias}
\end{figure}

Moving beyond the intensity of individual cells, we found that the square-root transformation benefited the power in our samples. More specifically, the average power over the spatial and temporal dimensions more closely aligns with the test set in samples generated via the square-root-transformation model. The improvement is observable over all scales, as demonstrated by the spatial and temporal PSD graphs in Figure \ref{fig:no_transform_vs_sqrt_psd}. The consistent enhancement suggests that the square-root transformation facilitates the model's ability to learn and represent the spatiotemporal features inherent in the true precipitation distribution with better proficiency.

\begin{figure}[htbp]
      \centering
      \begin{subfigure}{0.49\textwidth}
            \includegraphics[width=\linewidth]{no_transform_vs_sqrt_psd_spatial.png}
            \caption{Spatial Dimensions}
      \end{subfigure}
      \begin{subfigure}{0.49\textwidth}
            \includegraphics[width=\linewidth]{no_transform_vs_sqrt_psd_temporal.png}
            \caption{Temporal Dimension}
      \end{subfigure}
      \caption{PSD graphs for samples generated via our square-root transformed model, samples generated via our no-transformation model, and the test set from UKCP18. The format is the same as Figure \ref{fig:no_transform_psd}.}
      \label{fig:no_transform_vs_sqrt_psd}
\end{figure}

\section{Learning a Transformation}
\label{sec:results_learning_transformation}

In this section, we build upon the significant improvements achieved with the square-root transformation; we introduce an approach that enables our model to learn a transformation rather than depending on a predefined function. By facilitating the adaptive discovery of a suitable transformation, we posit that this approach may hold the potential for generalisation with different distributions, not limited to precipitation. This adaptability could prove particularly valuable for distributions lacking an easily identifiable transformation to enhance performance, thus offering a flexible solution to enhance the performance of diffusion models across various applications.

\subsection{Change of Variable Rule}
\label{sec:results_change_of_variable}

Suppose we transform our observed variable $\mathbf{x}$ via an element-wise vector-valued function $\mathbf{h}:[-1, 1]^D\to[-1,1]^D$, such that:
\begin{align}
      \mathbf{h}(\mathbf{x})=
      \begin{bmatrix}
            h(x_1) \\
            h(x_2) \\
            \vdots \\
            h(x_D)
      \end{bmatrix}
\end{align}
where $x_i$ is the $i$-th element of $\mathbf{x}$, and $h:[-1, 1]\to[-1,1]$ is a scalar-valued monotonically increasing function applied to each element of $\mathbf{x}$. The change of variable rule states that:
\begin{align}
      p_\theta(\mathbf{x}) = \tilde{p}_\theta(\mathbf{h}(\mathbf{x}))\left|\det\left(\frac{d \mathbf{h}(\mathbf{x})}{d \mathbf{x}}\right)\right|
\end{align}
where $\tilde{p}_\theta(\mathbf{h}(\mathbf{x}))$ is the probability density of our transformed observed variable $\mathbf{h}(\mathbf{x})$, $\det$ is the determinant operator, and $d\mathbf{h}(\mathbf{x})/d\mathbf{x}$ is the Jacobian of transformation $\mathbf{h}$. Since $\mathbf{h}$ is an element-wise transformation, the Jacobian matrix is diagonal:
\begin{align}
      \frac{d\mathbf{h}(\mathbf{x})}{d\mathbf{x}} =
      \begin{bmatrix}
            \frac{\partial \tilde{x}_1}{\partial x_1} & 0 & \cdots & 0 \\
            0 & \frac{\partial \tilde{x}_2}{\partial x_2} & \cdots & 0 \\
            \vdots & \vdots & \ddots & \vdots \\
            0 & 0 & \cdots & \frac{\partial \tilde{x}_D}{\partial x_D}
      \end{bmatrix}
\end{align}
The determinant of a diagonal matrix is simply the product of its elements; thus, we can write:
\begin{align}
      \det\left(\frac{d\mathbf{h}(\mathbf{x})}{d\mathbf{x}}\right) = \prod_{i=1}^D \frac{\partial h(x_i)}{\partial x_i}.
\end{align}
Therefore, we can rewrite the change of variables rule under transformation $\mathbf{h}$ in the following simplified form:
\begin{align}
      p_\theta(\mathbf{x}) = \tilde{p}_\theta(\mathbf{h}(\mathbf{x}))\prod_{i=1}^D \frac{\partial h(x_i)}{\partial x_i}
\end{align}
We can thus formulate the negative log-likelihood of $\mathbf{x}$ as follows:
\begin{align}
      -\log p_\theta(\mathbf{x}) &= -\log \left(\tilde{p}_\theta(\mathbf{h}(\mathbf{x}))\prod_{i=1}^D\frac{\partial h(x_i)}{\partial x_i}\right)\\
      &= -\log \tilde{p}_\theta(\mathbf{h}(\mathbf{x})) - \log\left(\prod_{i=1}^D\frac{\partial h(x_i)}{\partial x_i}\right)\\
      &= -\log \tilde{p}_\theta(\mathbf{h}(\mathbf{x})) - \sum_{i=1}^D \log \left(\frac{\partial h(x_i)}{\partial x_i}\right)\label{eq:minus_log_in_terms_of_minus_log_transform}
\end{align}

\subsection{ELBO Loss with a Change of Variable}
\label{sec:results_elbo_change_of_variable}

The ELBO loss for a transformed datapoint $\mathbf{h}(\mathbf{x})$, denoted $\tilde{\mathcal{L}}_{\mathrm{ELBO}}(\mathbf{h}(\mathbf{x}))$, serves as a variational bound on the negative log-likelihood of $\mathbf{h}(\mathbf{x})$ and is given by:
\begin{align}
      -\log \tilde{p}_\theta(\mathbf{h}(\mathbf{x}))\le \tilde{\mathcal{L}}_{\mathrm{ELBO}}(\mathbf{h}(\mathbf{x})) = \mathbb{E}_{\mathbf{z}_0,\ldots,\mathbf{z}_1\sim\tilde{q}(\mathbf{z}_0,\ldots,\mathbf{z}_1|\mathbf{h}(\mathbf{x}))} \left[\log \frac{\tilde{p}_\theta(\mathbf{z}_0,\ldots,\mathbf{z}_1,\mathbf{h}(\mathbf{x}))}{\tilde{q}(\mathbf{z}_0,\ldots,\mathbf{z}_1|\mathbf{h}(\mathbf{x}))}\right]
\end{align}
Plugging the inequality into Equation \ref{eq:minus_log_in_terms_of_minus_log_transform}, we obtain:
\begin{align}
      -\log p_\theta(\mathbf{x})\le \tilde{\mathcal{L}}_{\mathrm{ELBO}}(\mathbf{h}(\mathbf{x})) - \sum_{i=1}^D \log \left(\frac{\partial h(x_i)}{\partial x_i}\right)\label{eq:optimal_elbo_no_parameters}
\end{align}
Thus, if we were to parameterise the transformation $\mathbf{h}_\omega$, with transformative parameters $\omega$, we would theoretically be able to learn some optimal transformation that enables us to approximately minimise the negative log-likelihood of the observed variable $\mathbf{x}$. For completeness, the loss with transformative parameters $\omega$ yields only a minor modification to Equation \ref{eq:optimal_elbo_no_parameters} and is given by:
\begin{align}
      p_\theta(\mathbf{x}) \le \tilde{\mathcal{L}}_{\mathrm{ELBO}}(\mathbf{h}_\omega(\mathbf{x})) - \sum_{i=1}^D \log \left(\frac{\partial h_\omega(x_i)}{\partial x_i}\right)\label{eq:optimal_elbo_parameters}
\end{align}
However, as detailed in Section \ref{sec:background_diffusion_weighted_loss}, optimising our generative parameters $\theta$ via the ELBO loss yields suboptimal results. Diffusion models in the broader literature have achieved far superior results via optimisation with the weighted loss $\mathcal{L}_{\mathrm{WL}}$.

\subsection{Weighted Loss with a Change of Variable}

The $\lambda$-dependent weighting function $w(\lambda)$ in the weighted loss $\mathcal{L}_{\mathrm{WL}}$ causes it to lose a direct theoretical relationship with the negative log-likelihood of the observed variable $\mathbf{x}$. Thus, we cannot directly apply the change of variable approach to the weighted loss as we did for the ELBO loss. However, we can consider the individual contribution of the negative log-determinant term in the loss given in Equation \ref{eq:optimal_elbo_parameters} to derive a novel loss function for our diffusion model that jointly optimises the generative parameters $\theta$ and the transformative parameters $\omega$. Crucially, since we constrain the output range of $h_\omega$ to $[-1,1]$, the neural network cannot infinitely extend the output range. As such, it has to learn some optimal monotonically increasing function to minimise the negative log-determinant term.

Since the $\log$ function itself is monotonically increasing, the negative log-determinant term will intuitively encourage a steeper gradient for areas of the input space $[-1, 1]$ wherein individual elements $x_i$ occur most often. Conversely, the term will individually encourage a shallower gradient for areas of the input space $[-1, 1]$ wherein individual elements $x_i$ occur least often. Using this intuition, we hypothesised that we could add the negative log-determinant term to the weighted loss to jointly optimise the generative parameters $\theta$ and the transformative parameters $\omega$ to achieve higher-quality samples. We denote the weighted loss for a transformed datapoint $\mathbf{h}_\omega(\mathbf{x})$ by $\tilde{\mathcal{L}}_{\mathrm{WL}}(\mathbf{h}_\omega(\mathbf{x}))$, and thus our novel loss function is given by:
\begin{align}
      \tilde{\mathcal{L}}_{\mathrm{WL}}(\mathbf{h}_\omega(\mathbf{x})) - \sum_{i=1}^D \log \left(\frac{\partial h_\omega(x_i)}{\partial x_i}\right)\label{eq:weighted_loss_transform}
\end{align}

\subsection{Transformation Neural Network}

We utilise a simple neural network with two fully-connected hidden layers to learn the transformation $h_\omega$ from Equation \ref{eq:weighted_loss_transform}. The network contains only a single neuron in both the input and output layers and 16 neurons in each hidden layer; we use the $\tanh$ activation function for each neuron in both hidden layers and for the output neuron. We restrict all the weights---not including biases---to be positive to ensure the learnt transformation is monotonically increasing. Since the logarithm of zero is undefined, we add a small multiple of the input to the network's output to prevent the gradient from being zero at any point. We scale the output to the range $[-1,1]$.

\subsection{Improved Weighted Loss with a Change of Variable}

We found that, in practice, the weighted loss with a change of variable given in Equation \ref{eq:weighted_loss_transform} gave rise to poor-quality samples. The transformation it induced was too aggressive, with a significantly large gradient at the lowest end of the input space around $x_i=-1$. Consequently, except for that region, the learnt transformation was $h_\omega(x_i)\approx 1$. As such, the loss function gave rise to the effect depicted in Figure \ref{fig:bad_learnt_transform}. Constraining much of the input space to $h_\omega(x_i)\approx 1$ prevents the model from learning the distribution of the transformed observed variable $\mathbf{h}_\omega(\mathbf{x})$ correctly. As such, the samples contain unnaturally high precipitation rates: many areas depicted in Figure \ref{fig:bad_learnt_transform} receive over half a metre of precipitation over the ten hours.

\begin{figure}[htbp]
      \centering
      \includegraphics[width=\linewidth]{bad_learnt_transform.png}
      \caption{Randomly selected sample generated via our model trained with the loss function given in Equation \ref{eq:weighted_loss_transform}. The format is the same as Figure \ref{fig:no_transform_sample}.}
      \label{fig:bad_learnt_transform}
\end{figure}

To address this issue, we introduce two interventions which, in conjunction, we found to yield a significant improvement in the quality of the samples generated by our model. Firstly, we significantly increase the multiple by which we add the input to the transformation network to its output. Consequently, at no point is the gradient of the transformation less than a predetermined value. We thus refer to this small multiple as our \textit{minimum gradient coefficient}. Empirically, we found a minimum gradient coefficient of 0.1 yielded good results.

Secondly, we introduce a \textit{masking function}, denoted $m:[-1,1]\to \{0,1\}$, that takes a single element $x_i$ of some datapoint $\mathbf{x}$ as input and outputs a binary value:
\begin{align}
      m(x_i)=\begin{cases}
            1 & \text{if } x_i\in \mathcal{M}\\
            0 & \text{otherwise}
      \end{cases}
\end{align}
where $\mathcal{M}\subseteq[-1, 1]$ is a pre-defined masking set with no learnable parameters, which we use to assert greater control over the transformation learnt by our transformation neural network. We incorporate the masking function into our loss given in Equation \ref{eq:weighted_loss_transform} to yield:
\begin{align}
      \tilde{\mathcal{L}}_{\mathrm{WL}}(\mathbf{h}_\omega(\mathbf{x})) - \sum_{i=1}^D \log \left(\frac{\partial h_\omega(x_i)}{\partial x_i}\right)\cdot m(x_i)\label{eq:weighted_loss_transform_masked}
\end{align}
As such, we can use the masking function and masking set to influence the gradient of the learnt transformation. Only elements $x_i$ within the masking set $\mathcal{M}$ will contribute to the negative log-determinant term in the loss. On one end of the scale, if we were to set $\mathcal{M}=[-1,1]$, this would equate to the loss of Equation \ref{eq:weighted_loss_transform}. Conversely, if we were to set $\mathcal{M}=\emptyset$, then the log-determinant term would be redundant---it would never contribute to the loss. Empirically, we found $\mathcal{M}=[-0.99975, 1]$ prevented the transformation network from learning too extreme a transformation. In simple terms, we prevent the elements of our training set that are extremely small---to the extent that they can almost be considered `dry' for all practical intents and purposes---contributing to the transformation. Figure \ref{fig:learnt_transform} shows the transformation learnt by our model trained with the loss function given in Equation \ref{eq:weighted_loss_transform_masked}. We refer to this model as out \textit{learnt-transformation model} for brevity.

\begin{figure}[htbp]
      \centering
      \includegraphics[width=.5\linewidth]{learnt_transform.png}
      \caption{The transformation learnt by our model trained with the loss function given in Equation \ref{eq:weighted_loss_transform_masked}. The horizontal axis is the value of some element $x_i\in[-1, 1]$ input to the transformation network; the vertical axis is the corresponding output $h_\omega(x_i)\in [-1, 1]$.}
      \label{fig:learnt_transform}
\end{figure}

Importantly, for both of these solutions, we did not conduct any systematic hyperparameter search; thus, it is likely that more optimal combinations of the minimum gradient coefficient and masking set exist.

\subsection{Evaluation of the Learnt Transformation}

To evaluate the performance of our model with the learnt transformation, we primarily focus our analysis against benchmarks set by our square-root-transformation model since it outperformed our no-transformation model by most measures.

Notably, samples generated via our learnt-transformation model better capture the true frequency of individual precipitation intensities for most rates observed in the test set, as evident from Figure \ref{fig:learnt_transform_vs_sqrt_histogram}. In particular, our learnt-transformation model outperforms our square-root-transformation model in every one-millimetre-per-hour interval up to six millimetres-per-hour. Due to the skewed distribution of precipitation, this represents all but the 0.01\% most intense precipitation, as evident from the QQ plot in Figure \ref{fig:learnt_transform_vs_sqrt_qq}. Beyond this region, our learnt-transformation model similarly excels at capturing precipitation with intensities of 10--26 millimetres per hour, with a 15\% absolute reduction on average in the relative discrepancy in frequency compared to our square-root-transformation model. In all other regions, the dominance of either model is less clear.

\begin{figure}[htbp]
      \centering
      \includegraphics[width=\textwidth]{learnt_transform_vs_sqrt_histogram.png}
      \caption{Distribution of precipitation rates in samples generated via our learnt-transformation model compared to samples generated via our square-root-transformation model and the test set from UKCP18. The format is the same as Figure \ref{fig:no_transform_histogram}.}
      \label{fig:learnt_transform_vs_sqrt_histogram}
\end{figure}

\begin{figure}[htbp]
      \centering
      \includegraphics[width=\textwidth]{learnt_transform_vs_sqrt_qq.png}
      \caption{QQ plots for individual cells within the test set from UKCP18 against both samples generated via our square-root-transformation model and samples generated via our learnt-transformation model. The format is the same as Figure \ref{fig:no_transform_qq}. $\mathcal{Q} = \{1 - 10^{-n_1} + n_2 \cdot 10^{-n_1 - 1}\mid n_1,n_2\in \mathbb{N}, 1 \le n_2 \le 9\}$.}
      \label{fig:learnt_transform_vs_sqrt_qq}
\end{figure}

Figure \ref{fig:learnt_transform_bias} depicts the mean-normalised bias at each $8.8\ \mathrm{km}\times 8.8\ \mathrm{km}$ subarea in samples generated via our learnt-transformation model. We observe a remarkable improvement in the mean-normalised bias in almost all subareas compared to that of the square-root transformation model in Figure \ref{fig:sqrt_bias}. We attribute this improvement to the decreased overrepresentation of precipitation below one millimetre per hour, which account for approximately 97\% of all intensities in our test set. As a direct result, our learnt-transformation model equally lessens the underrepresentation of more intense precipitation. Thus, the mean precipitation intensity in the generated samples is significantly higher in almost all subareas. 

\begin{figure}[htbp]
      \centering
      \includegraphics[width=.5\textwidth]{learnt_transform_bias.png}
      \caption{Mean-normalised bias at each cell representing the same $8.8\ \mathrm{km}\times 8.8\ \mathrm{km}$ geographical area in the samples generated via our learnt-transformation model.}
      \label{fig:learnt_transform_bias}
\end{figure}

Interestingly, we observe a notable positive linear association---characterised by a coefficient of determination of 0.59---between the mean-normalised bias of a given subarea in samples generated via our no-transformation model and those generated via our square-root transformation model, as evident from the scatter plot in Figure \ref{fig:learnt_transform_vs_sqrt_bias_scatter}. Similar to our square-root-transformation model, our learnt-transformation model exhibits particularly pronounced bias in Central England, East of England, London and South East England. We also observe an apparent relationship with the mean-normalised bias of the coarsened-CPM-driven samples generated via Addison et al. \cite{Addison_Machine_Learning_Emulation}. These associations contrast with the absence of any discernible relationship between the mean-normalised bias of a given subarea in samples generated via our square-root-transformation model and those generated via our learnt-transformation model. The contrasting associations potentially warrant further exploration in future work to gain a deeper understanding of the underlying causes and potential implications of different transformation techniques on model performance.

\begin{figure}[htbp]
      \centering
      \includegraphics[width=.5\textwidth]{learnt_transform_vs_sqrt_bias_scatter.png}
      \caption{Relationship between the mean-normalised bias at each cell representing the same $8.8\ \mathrm{km}\times 8.8\ \mathrm{km}$ geographical area in the samples generated via our square-root-transformation model and our learnt-transformation model. The horizontal axis is the mean-normalised bias for the square-root transformation; the vertical axis is the mean-normalised bias for the learnt transformation. The black line shows linear regression with a coefficient of determination of $R^2 = 0.59$.}
      \label{fig:learnt_transform_vs_sqrt_bias_scatter}
\end{figure}

Although the dominance of our learnt-transformation model is not absolute regarding capturing the distribution of individual precipitation intensities, our study demonstrates that it consistently outperforms in terms of the power in its generated samples. At any given temporal or spatial resolution, the power in samples produced via our learnt-transformation model is closer to the power in our test set from UKCP18 than those produced via our square-root-transformation model, as evident in Figure \ref{fig:learnt_transform_vs_sqrt_psd}. The power at each scale is, on average, 50\% lower in samples generated via the square-root transformation model in both the spatial and temporal dimensions. For our learnt-transformation model, the discrepancy reduces to 45\%, an absolute reduction of 5\%. These improvements suggest that enabling the model to learn its transformation empowers it to learn precipitation's spatial and temporal characteristics more effectively.

\begin{figure}[htbp]
      \centering
      \begin{subfigure}{.49\textwidth}
            \includegraphics[width=\linewidth]{learnt_transform_vs_sqrt_psd_spatial.png}
            \caption{Spatial Dimensions}
            \label{fig:learnt_transform_vs_sqrt_psd_spatial}
      \end{subfigure}
      \begin{subfigure}{.49\textwidth}
            \includegraphics[width=\linewidth]{learnt_transform_vs_sqrt_psd_temporal.png}
            \caption{Temporal Dimension}
            \label{fig:learnt_transform_vs_sqrt_psd_temporal}
      \end{subfigure}
      \caption{PSD graphs for samples generated via our learnt-transformation model, our square-root-transformation model and the test set from UKCP18. The format is the same as Figure \ref{fig:no_transform_psd}.}
      \label{fig:learnt_transform_vs_sqrt_psd}
\end{figure}

Our analysis demonstrates that our learnt-transformation model consistently outperforms the square-root-transformation model in several key aspects. These aspects include capturing the true frequency of individual precipitation rates for most intensities, reducing the mean-normalised bias in generated samples, and offering better power across the spatial and temporal domains at all scales. We attribute the improved performance to the ability of the learnt-transformation model to learn a suitable transformation for the given data. Moreover, the adaptability of our approach holds potential for generalisation to different distributions---not limited to precipitation---thus offering a flexible and powerful solution for enhancing the performance of diffusion models across various potential applications. Although the dominance of our leant-transformation model is not absolute, we believe the overall improvements warrant further exploration and refinement in future work.

\begin{figure}[htbp]
      \centering
      \begin{subfigure}{\textwidth}
            \includegraphics[width=\linewidth]{learnt_transform_sample.png}
      \end{subfigure}
      \begin{subfigure}{\textwidth}
            \includegraphics[width=\linewidth]{learnt_transform_sample_2.png}
      \end{subfigure}
      \begin{subfigure}{\textwidth}
            \includegraphics[width=\linewidth]{learnt_transform_sample_3.png}
      \end{subfigure}
      \caption{Three samples generated via our learnt-transformation model. The format is the same as Figure \ref{fig:no_transform_sample}.}
      \label{fig:learnt_transform_sample}
\end{figure}

% \begin{figure}[htbp]
%       \centering
%       \includegraphics[width=\linewidth]{learnt_transform_sample_2.png}
%       \caption{Sample generated via our model trained with the loss function given in Equation \ref{eq:weighted_loss_transform_masked}. The format is the same as Figure \ref{fig:no_transform_sample}.}
%       \label{fig:learnt_transform_sample_2}
% \end{figure}

\section{Temporal Interpolation}
\label{sec:results_temporal_interpolation}

In Section \ref{sec:background_diffusion_reconstruction_guided_sampling}, we detailed reconstruction-guided sampling \cite{VDM_Ho} as a technique for deriving a conditional diffusion model approximately from an unconditional model. In this section, we employ this method to facilitate \textit{temporal interpolation}: the generation of intermediate samples between known samples in a sequence. The critical contribution of this section lies in demonstrating the potential of reconstruction-guided sampling to facilitate the generation of hourly precipitation samples that maintain coherency with adjacent samples of a bi-hourly temporal resolution. We emphasise the crucial role of the reconstruction-guidance weight in achieving this goal.

Temporal interpolation of precipitation holds the potential to significantly benefit numerous real-world applications, such as the generation of high-resolution climate simulations. As detailed in Section \ref{sec:background_climate_downscaling}, the extensive computational cost of producing such simulations hinders their widespread deployment \cite{MO_CPM}. Developing efficient interpolation techniques could address this challenge by enabling the generation of high-resolution climate simulations through a two-step process: initially generating data at a lower temporal resolution, followed by interpolating it to the desired temporal resolution. The benefits of such an approach hinge on two crucial aspects: ensuring that the computational savings realised during the initial generation of lower temporal resolution data are not negated by the cost of the subsequent interpolation process and the effectiveness of the interpolation technique in maintaining the coherence of the interpolated samples. Reconstruction-guided sampling plausibly contributes to the former by enabling multiple conditional generation tasks using a single unconditional model, thereby circumventing the need for separate conditional models for each task, which would incur significant computational expenses. Nevertheless, in the present study, our primary emphasis is on the latter: providing a proof of principle for temporal interpolation in the context of time-evolving hourly precipitation data while reserving a comprehensive analysis of the computational cost trade-offs for future research.

As demonstrated by Figure \ref{fig:interpolate_histogram} and Figure \ref{fig:interpolate_qq}, the quality of the interpolated samples is highly contingent upon an adequately high reconstruction-guidance weight. With a reconstruction-guidance weight of $w_r=0$, our conditional sampling procedure is equivalent to the imputation method \cite{Score_Based_Song} and results in a distribution that significantly deviates from the observed distribution, particularly in the underestimation of the probability of more intense precipitation. Interestingly, even with a reconstruction-guidance weight of $w_r=10^3$, the improvement over the imputation method remains marginal.

\begin{figure}[htbp]
      \centering
      \includegraphics[width=\linewidth]{interpolate_histogram.png}
      \caption{Distribution of individual precipitation rates in the conditionally generated interpolated samples produced by our learnt-transformation model with varying reconstruction-guidance weights and the observed distribution of the corresponding withheld samples from 12 seasons in our test set. The format is the same as Figure \ref{fig:no_transform_histogram}.}
      \label{fig:interpolate_histogram}
\end{figure}

\begin{figure}[htbp]
      \centering
      \includegraphics[width=\textwidth]{interpolate_qq.png}
      \caption{QQ plot comparing the distribution of individual precipitation rates in the conditionally generated interpolated samples produced by our learnt-transformation model with varying reconstruction-guidance weights against the corresponding observed withheld samples from 12 seasons in our test set. The format is the same as Figure \ref{fig:no_transform_qq}.}
      \label{fig:interpolate_qq}
\end{figure}

By employing a reconstruction-guidance weight of $w_r=10^6$, we obtain a distribution closely resembling the observed distribution of the corresponding withheld samples from the test set. We can regard the limitations observed in the interpolated samples generated with a low reconstruction-guidance weight as accentuated manifestations of the shortcomings inherent in our unconditional model. Specifically, samples generated in the unconditional setting tend to underrepresent the probability of more intense precipitation, a problem mirrored and magnified in the interpolated samples generated under a low reconstruction-guidance weight. Intriguingly, utilising a sufficiently large reconstruction-guidance weight effectively mitigates these issues, resulting in interpolated samples that better represent the probability of more intense precipitation.

In examining the spatial characteristics of the interpolated samples, we observe a similar trend, as illustrated in Figure \ref{fig:interpolate_psd_spatial}. Notably, interpolated samples generated with a reconstruction-guidance weight of $w_r=0$ or $w_r=10^3$ exhibit power in the spatial dimensions that significantly deviates from the corresponding withheld samples in the test set. In contrast, when utilising a reconstruction-guidance weight of $w_r=10^6$, the power in the spatial dimensions of the interpolated samples closely aligns with that of the corresponding withheld samples.

The temporal PSD graph in Figure \ref{fig:interpolate_psd_temporal} further supports this trend, reinforcing the inadequacy of lower reconstruction-guidance weights. We observe that the interpolated samples generated with a lower weighting have significantly too much power at the lowest temporal scales, attributable to the deviation in the distribution of individual precipitation intensities. More specifically, due to the substantial deviation in the distribution of individual intensities, the interpolated samples bear little resemblance to their adjacent samples, resulting in a high power at the most minute temporal scales. However, when employing a reconstruction-guidance weight of $w_r=10^6$, the temporal PSD graph of the interpolated samples is remarkably similar to that of the corresponding withheld samples. The most pronounced deviation similarly occurs at the lowest temporal scale, albeit to a significantly lesser extent.

Figure \ref{fig:interpolate_sample} further underscores the critical role of the reconstruction-guidance weight by visually representing a single interpolated sample generated with different weightings; only the hourly samples generated with a weight of $w_r=10^6$ exhibit a resemblance to the corresponding withheld samples from the test set.

\begin{figure}[htbp]
      \centering
      \begin{subfigure}{.49\textwidth}
            \includegraphics[width=\linewidth]{interpolate_psd_spatial.png}
            \caption{Spatial Dimensions}
            \label{fig:interpolate_psd_spatial}
      \end{subfigure}
      \begin{subfigure}{.49\textwidth}
            \includegraphics[width=\linewidth]{interpolate_psd_temporal.png}
            \caption{Temporal Dimension}
            \label{fig:interpolate_psd_temporal}
      \end{subfigure}
      \caption{PSD graphs for the conditionally generated samples generated via our learnt-transformation model with different reconstruction-guidance weights and observed withheld samples from 12 seasons in our test set. The format is the same as Figure \ref{fig:no_transform_psd}. Spatial power calculations are based solely on interpolated samples; temporal power calculations consider the entire sequence, incorporating both interpolated samples and those conditioned on that have a bi-hourly temporal resolution.}
      \label{fig:interpolate_psd}
\end{figure}

\begin{figure}[htbp]
      \centering
      \begin{subfigure}{\textwidth}
            \includegraphics[width=\linewidth]{interpolate_real.png}
            \caption{Observed sample in UKCP18}
            \label{fig:interpolate_sample_real}
      \end{subfigure}
      \begin{subfigure}{\textwidth}
            \includegraphics[width=\linewidth]{interpolate_wr_0.png}
            \caption{Generated interpolations with $w_r=0$}
            \label{fig:interpolate_sample_wr_0}
      \end{subfigure}
      \begin{subfigure}{\textwidth}
            \includegraphics[width=\linewidth]{interpolate_wr_1k.png}
            \caption{Generated interpolations with $w_r=10^3$}
            \label{fig:interpolate_sample_wr_1k}
      \end{subfigure}
      \begin{subfigure}{\textwidth}
            \includegraphics[width=\linewidth]{interpolate_wr_1m.png}
            \caption{Generated interpolations with $w_r=10^6$}
            \label{fig:interpolate_sample_wr_1m}
      \end{subfigure}
      \caption{Temporally interpolated samples generated via our learnt-transformation model. Figure \ref{fig:interpolate_sample_real} depicts the observed sample in UKCP18, with the hourly snapshots conditioned on highlighted in red. The three subsequent figures depict interpolated samples generated with different reconstruction-guidance weights; captions below each figure indicate the reconstruction-guidance weight $w_r$. Ideally, each hourly snapshot should be identical, or very similar, to the corresponding true snapshot in Figure \ref{fig:interpolate_sample_real}. The format of each hourly snapshot is the same as Figure \ref{fig:no_transform_sample}.}
      \label{fig:interpolate_sample}
\end{figure}

In summary, this section establishes the potential for generating interpolated samples with a distribution of individual intensities and spatiotemporal characteristics that closely resemble the corresponding withheld samples from the test set, achieved by employing an adequate reconstruction-guidance weight. The discrepancies observed between the interpolated and corresponding withheld samples are considerably less pronounced than those observed in the unconditional setting, making the results particularly encouraging. Despite the model's inherent limitations in the unconditional context, a substantial reconstruction-guidance weight allows the same unconditional model to generate interpolated samples that overcome these limitations.

\section{Nowcasting}
\label{sec:results_nowcasting}

Following the successful application of reconstruction-guided sampling for temporal interpolation, as demonstrated in the previous section, we extend our study to its potential applicability for nowcasting. This section presents preliminary proof-of-principle results for using a diffusion model to generate nowcasts.

As demonstrated by Figure \ref{fig:nowcast_histogram} and Figure \ref{fig:nowcast_qq}, the distribution of individual intensities in the conditionally generated nowcasts resembles the distribution of the corresponding withheld samples from the test set. The similar distribution suggests that the nowcasts broadly contain the correct amount of precipitation. However, there are notable discrepancies. Specifically, the nowcasts underrepresent precipitation less intense than 10 millimetres per hour and overrepresent more intense precipitation. Interestingly, the discrepancies appear to be accentuated versions of those observed in the interpolated samples generated with an identical reconstruction-guidance weight of $w_r=10^6$. This similarity suggests that developing techniques to address the discrepancies in the interpolated samples may also apply to the nowcasts and vice versa.

\begin{figure}[htbp]
      \centering
      \includegraphics[width=\linewidth]{nowcast_histogram.png}
      \caption{Distribution of individual precipitation rates in the conditionally generated nowcasts produced by our learnt-transformation model, and the observed distribution of the corresponding withheld samples from 12 seasons in our test set. The format is the same as Figure \ref{fig:no_transform_histogram}.}
      \label{fig:nowcast_histogram}
\end{figure}

\begin{figure}[htbp]
      \centering
      \includegraphics[width=\textwidth]{nowcast_qq.png}
      \caption{QQ plot comparing the distribution of individual precipitation rates in the conditionally generated nowcasts produced by our learnt-transformation model against the corresponding observed withheld samples from 12 seasons in our test set. The format is the same as Figure \ref{fig:no_transform_qq}.}
      \label{fig:nowcast_qq}
\end{figure}

Figure \ref{fig:nowcast_psd} depicts PSD graphs for the spatial and temporal dimensions of the nowcasts and the corresponding withheld samples from the test set. As evident from the spatial PSD graph in Figure \ref{fig:nowcast_psd_spatial}, the nowcasts exhibit similar spatial characteristics to their corresponding withheld samples from the test set. The similarity is better at more minor spatial scales; at the most minute spatial scale, the difference in power is negligible. At all scales, the discrepancy between the nowcasts and the withheld samples is less pronounced than the discrepancy between the unconditionally generated samples and the test set. The consistently lesser discrepancy reaffirms our earlier observation that an adequate reconstruction-guidance weight enables the same unconditional model to generate samples conditionally that partially overcome the model's inherent limitations in the unconditional setting. 

\begin{figure}[htbp]
      \centering
      \begin{subfigure}{.47\textwidth}
            \includegraphics[width=\linewidth]{nowcast_psd_spatial.png}
            \caption{Spatial Dimensions}
            \label{fig:nowcast_psd_spatial}
      \end{subfigure}
      \begin{subfigure}{.51\textwidth}
            \includegraphics[width=\linewidth]{nowcast_psd_temporal.png}
            \caption{Temporal Dimension}
            \label{fig:nowcast_psd_temporal}
      \end{subfigure}
      \caption{PSD graphs for conditionally generated nowcasts produced via our learnt-transformation model against the corresponding observed withheld samples from 12 seasons in our test set. The format is the same as Figure \ref{fig:no_transform_psd}.}
      \label{fig:nowcast_psd}
\end{figure}

Figure \ref{fig:nowcast_sample} presents a nowcast sample generated by our model, which showcases the model's proficiency in several aspects. In particular, the model demonstrates its merit in accurately capturing the easterly movement of the precipitation band, as evidenced by the alignment of the predicted and actual precipitation patterns. Moreover, the model exhibits its ability to capture the correct movement of the precipitation band. For instance, in the final snapshot provided to the model, the precipitation band is just entering the South West of England. Remarkably, the nowcast reveals that the model has adeptly captured the band's progress, extending as far as Exteter four hours later. The model has also successfully identified the relative immobility of the most easterly part of the precipitation band. In the final snapshot provided to the model, the most easterly segment of the band has a longitude of approximately 1.5 degrees west. In both the nowcast five hours later and the corresponding observed snapshot, the most easterly segment of the band similarly has a longitude of approximately 1.5 degrees west.

\begin{figure}[htbp]
      \centering
      \begin{subfigure}{\textwidth}
            \includegraphics[width=\linewidth]{nowcast_sample_real.png}
            \caption{Observed sample in UKCP18}
            \label{fig:nowcast_sample_real}
      \end{subfigure}
      \begin{subfigure}{\textwidth}
            \includegraphics[width=\linewidth]{nowcast_sample_predict.png}
            \caption{Generated nowcast with $w_r=10^6$}
            \label{fig:nowcast_sample_predict}
      \end{subfigure}
      \caption{Nowcast sample generated via our learnt-transformation model. Figure \ref{fig:nowcast_sample_real} depicts an observed sample in UKCP18, with the hourly samples conditioned on in the subsequent nowcast highlighted in red. Figure \ref{fig:nowcast_sample_predict} depicts the corresponding nowcast. Ideally, each hourly snapshot in the nowcast should resemble the corresponding observed snapshot. The format of each hourly snapshot is the same as Figure \ref{fig:no_transform_sample}.}
      \label{fig:nowcast_sample}
\end{figure}

In summary, this section establishes a proof-of-principle for the ability of diffusion models to generate nowcasts. We leave the development of techniques to address the discrepancies observed in the nowcasts and a more comprehensive analysis for future work.

% \section{Autoregressive Generation of Longer Sequences}

% One of the primary limitations of our current model is a constraint on the length of our generated samples, which is limited to ten hours. This limitation stems from the fact that the generated samples possess the same dimensionality as the training data; in the temporal dimension, this corresponds to only ten hours.

% To address this issue, we provide initial results for using reconstruction-guided sampling to facilitate the autoregressive generation of arbitrarily long samples. In this respect, we generate the next set of samples by conditioning on the previous set of samples.

% This autoregressive strategy enables the creation of arbitrarily long samples, thus overcoming the inherent constraints of the unconditional diffusion model.

% -----------------------------------------------------------------------------

\chapter{Conclusion}
\label{chap:conclusion}

\section{Main Contributions}

To conclude, we summarise the main contributions of this work as follows. Firstly, we have successfully adopted techniques developed for video diffusion models, such as the 3D U-Net architecture \cite{VDM_Ho}, to create a diffusion model suitable for generating time-evolving precipitation fields.

Secondly, we have demonstrated in excruciating detail the impact that a transformation of the input during the training procedure has on the quality of the samples generated by a diffusion model. We have demonstrated that employing a suitable transformation---in this work, the square-root transformation---can significantly improve sample quality. Furthermore, we have introduced a novel loss function that facilitates simultaneous optimisation of the input transformation and generative parameters. We found that our model trained with this loss function produces higher-quality samples than models trained with the standard weighted loss, both with no transformation and with the square-root transformation.

Thirdly, in the context of conditional modelling, we have highlighted the importance of reconstruction-guided sampling \cite{VDM_Ho}. Our results show that this approach yields significantly higher-quality interpolated samples than the imputation method. We have also demonstrated that selecting an adequately high reconstruction-guidance weight is crucial for obtaining high-quality samples without the limitations observed in the unconditional context.

Lastly, we have similarly employed reconstruction-guided sampling to obtain initial proof-of-principle results for nowcasting. We found our model to generate nowcasts that reasonably capture the distribution of individual intensities and spatiotemporal characteristics of the observed samples.

\section{Future Work}

Due to the proof-of-principle nature of our work, we have appropriately identified several crucial avenues for future research.

Firstly, the underprediction of precipitation remains the primary limitation of our model in the unconditional context and thus represents a significant avenue for future work. Although we found that a transformation of the input partially mitigates this issue, a more optimal solution may involve self-learnt feature maps, as proposed by Addison et al. \cite{Addison_Machine_Learning_Emulation}. However, our inclusion of a temporal dimension may complicate this due to GPU memory constraints; nonetheless, we recommend this as a promising avenue for future work.

Secondly, while we have demonstrated the efficacy of reconstruction-guided sampling in the conditional domain, we recommend that future work conduct similar experiments with an explicitly-trained conditional model. Doing so would facilitate a more comprehensive analysis of the trade-offs between sample quality and computational cost.

Thirdly, we suggest future work to more comprehensively explore the potential of diffusion models for nowcasting. While our initial results indicate their ability to capture the future distribution of individual precipitation intensities and spatiotemporal characteristics, a more detailed analysis in this domain is warranted.

Lastly, outside of the climate domain, it would be interesting to investigate the influence of a transformation of the input on the quality of the generated samples. In this respect, we encourage future work to apply our novel loss function, which jointly optimises the input transformation and generative parameters, to other datasets and applications.

% =============================================================================

% Finally, after the main matter, the back matter is specified.  This is
% typically populated with just the bibliography.  LaTeX deals with these
% in one of two ways, namely
%
% - inline, which roughly means the author specifies entries using the 
%   \bibitem macro and typesets them manually, or
% - using BiBTeX, which means entries are contained in a separate file
%   (which is essentially a databased) then inported; this is the 
%   approach used below, with the databased being dissertation.bib.
%
% Either way, the each entry has a key (or identifier) which can be used
% in the main matter to cite it, e.g., \cite{X}, \cite[Chapter 2}{Y}.
%
% We would recommend using BiBTeX, since it guarantees a consistent referencing style 
% and since many sites (such as dblp) provide references in BiBTeX format. 
% However, note that by default, BiBTeX will ixwgnore capital letters in article titles 
% to ensure consistency of style. This can lead to e.g. "NP-completeness" becoming
% "np-completeness". To avoid this, make sure any capital letters you want to preserve
% are enclosed in braces in the .bib, e.g. "{NP}-completeness".

\backmatter

\bibliography{dissertation}

% -----------------------------------------------------------------------------

% The dissertation concludes with a set of (optional) appendicies; these are 
% the same as chapters in a sense, but once signaled as being appendicies via
% the associated macro, LaTeX manages them appropriatly.

% \appendix

% =============================================================================

\end{document}
